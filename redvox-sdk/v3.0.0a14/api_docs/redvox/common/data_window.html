<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.1" />
<title>redvox.common.data_window API documentation</title>
<meta name="description" content="This module creates specific time-bounded segments of data for users" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>redvox.common.data_window</code></h1>
</header>
<section id="section-intro">
<p>This module creates specific time-bounded segments of data for users</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
This module creates specific time-bounded segments of data for users
&#34;&#34;&#34;
import pandas as pd
import numpy as np
from typing import Optional, Set
from dataclasses import dataclass
from redvox.common import date_time_utils as dtu
from redvox.common.sensor_data import SensorType
from redvox.common.load_sensor_data import ReadResult, read_all_in_dir


DEFAULT_GAP_TIME_S: float = 0.25
DEFAULT_START_PADDING_S: float = 120.
DEFAULT_END_PADDING_S: float = 120.


@dataclass
class DataWindow:
    &#34;&#34;&#34;
    Holds the data for a given time window; adds interpolated timestamps to fill gaps and pad start and end values
    Properties:
        input_directory: string, directory that contains the files to read data from.  REQUIRED
        station_ids: optional set of strings, list of station ids to filter on.
                        If empty or None, get any ids found in the input directory.  Default None
        start_datetime: optional datetime, start datetime of the window.
                        If None, uses the first timestamp of the filtered data.  Default None
        end_datetime: optional datetime, end datetime of the window.
                        If None, uses the last timestamp of the filtered data.  Default None
        start_padding_s: float, the amount of seconds to include before the start_datetime
                            when filtering data.  Default DEFAULT_START_PADDING_S
        end_padding_s: float, the amount of seconds to include after the end_datetime
                        when filtering data.  Default DEFAULT_END_PADDING_S
        gap_time_s: float, the minimum amount of seconds between data points that would indicate a gap.
                    Default DEFAULT_GAP_TIME_S
        apply_correction: bool, if True, update the timestamps in the data based on best station offset.  Default False
        structured_layout: bool, if True, the input_directory contains specially named and organized
                            directories of data.  Default False
        stations: optional ReadResult, the results of reading the data from input_directory
    &#34;&#34;&#34;
    input_directory: str
    station_ids: Optional[Set[str]] = None
    start_datetime: Optional[dtu.datetime] = None
    end_datetime: Optional[dtu.datetime] = None
    start_padding_s: float = DEFAULT_START_PADDING_S
    end_padding_s: float = DEFAULT_END_PADDING_S
    gap_time_s: float = DEFAULT_GAP_TIME_S
    apply_correction: bool = False
    structured_layout: bool = False
    stations: Optional[ReadResult] = None

    def __post_init__(self):
        &#34;&#34;&#34;
        loads the data after initialization
        &#34;&#34;&#34;
        if self.stations is None:
            self.read_data()

    def copy(self) -&gt; &#39;DataWindow&#39;:
        &#34;&#34;&#34;
        :return: a copy of the DataWindow
        &#34;&#34;&#34;
        return DataWindow(self.input_directory, self.station_ids, self.start_datetime, self.end_datetime,
                          self.start_padding_s, self.end_padding_s, self.gap_time_s,
                          self.apply_correction, self.structured_layout, self.stations)

    def _has_time_window(self) -&gt; bool:
        &#34;&#34;&#34;
        Returns true if there is a start or end datetime in the settings
        :return: True if start_datetime or end_datetime exists
        &#34;&#34;&#34;
        return self.start_datetime is not None or self.end_datetime is not None

    def _pad_start_datetime_s(self) -&gt; float:
        &#34;&#34;&#34;
        apply padding to the start datetime
        :return: padded start datetime as seconds since epoch UTC
        &#34;&#34;&#34;
        return dtu.datetime_to_epoch_seconds_utc(self.start_datetime) - self.start_padding_s

    def _pad_end_datetime_s(self) -&gt; float:
        &#34;&#34;&#34;
        apply padding to the end datetime
        :return: padded end datetime as seconds since epoch UTC
        &#34;&#34;&#34;
        return dtu.datetime_to_epoch_seconds_utc(self.end_datetime) + self.end_padding_s

    def correct_timestamps(self):
        &#34;&#34;&#34;
        update the timestamps in all stations
        &#34;&#34;&#34;
        for station in self.stations.station_id_uuid_to_stations.values():
            if self.apply_correction:
                station.update_timestamps()

    def data_padder(self, data_df: pd.DataFrame, sample_interval_s: float) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        Pad the start and end of the dataframe with np.nan
        :param data_df: dataframe with timestamps as column &#34;timestamps&#34;
        :param sample_interval_s: constant sample interval in seconds
        :return: dataframe padded with np.nans in front and back to meet full size of expected start and end
        &#34;&#34;&#34;
        # extract the necessary information to pad the data
        data_time_stamps = data_df.sort_values(&#34;timestamps&#34;)[&#34;timestamps&#34;].to_numpy()
        first_data_timestamp = data_time_stamps[0]
        last_data_timestamp = data_time_stamps[-1]
        expected_start = dtu.datetime_to_epoch_microseconds_utc(self.start_datetime)
        expected_end = dtu.datetime_to_epoch_microseconds_utc(self.end_datetime)
        result_df = data_df.copy()
        # FRONT/END GAP FILL!  calculate the audio samples missing based on inputs
        if expected_start &lt; first_data_timestamp:
            start_diff = first_data_timestamp - expected_start
            num_missing_samples = int(dtu.microseconds_to_seconds(start_diff) / sample_interval_s) + 1
            # add the gap data to the result dataframe
            result_df = result_df.append(create_empty_df(expected_start -
                                                         dtu.seconds_to_microseconds(sample_interval_s),
                                                         sample_interval_s, data_df.columns,
                                                         num_missing_samples), ignore_index=True)
        if expected_end &gt; last_data_timestamp:
            last_diff = expected_end - last_data_timestamp
            num_missing_samples = int(dtu.microseconds_to_seconds(last_diff) / sample_interval_s) + 1
            # add the gap data to the result dataframe
            result_df = result_df.append(create_empty_df(expected_end +
                                                         dtu.seconds_to_microseconds(sample_interval_s),
                                                         sample_interval_s, data_df.columns,
                                                         num_missing_samples, True), ignore_index=True)
        return result_df.sort_values(&#34;timestamps&#34;, ignore_index=True)

    def read_data(self):
        &#34;&#34;&#34;
        read data using the properties of the class
        &#34;&#34;&#34;
        start_time = int(self._pad_start_datetime_s()) if self.start_datetime else None
        end_time = int(self._pad_end_datetime_s()) if self.end_datetime else None
        self.stations = read_all_in_dir(self.input_directory, start_time, end_time,
                                        self.station_ids, self.structured_layout)

        ids_to_pop = []
        # check if ids in station data from files
        for ids in self.station_ids:
            if not self.stations.check_for_id(ids):
                # error handling
                print(f&#34;WARNING: {ids} doesn&#39;t have any data to read&#34;)
            elif not self.stations.get_station(ids).has_audio_data():
                # no audio data is about the same as no data
                print(f&#34;WARNING: {ids} doesn&#39;t have any audio data to read&#34;)
                ids_to_pop.append(ids)
        for ids in ids_to_pop:
            self.stations.pop_station(ids)
        # calculate time differences in audio samples
        for station in self.stations.get_all_stations():
            # apply time correction
            if self.apply_correction:
                station.update_timestamps()
            for packet in range(len(station.packet_data) - 1):
                data_start = station.packet_data[packet].data_start_timestamp
                data_num_samples = station.packet_data[packet].packet_num_audio_samples
                next_packet_start_index = \
                    station.audio_sensor().data_df.query(&#34;timestamps == @data_start&#34;).first_valid_index() + \
                    data_num_samples
                data_end = station.audio_sensor().data_timestamps()[next_packet_start_index - 1]
                next_packet_start = station.audio_sensor().data_timestamps()[next_packet_start_index]
                if next_packet_start - data_end &lt; dtu.seconds_to_microseconds(self.gap_time_s):
                    station.packet_data[packet].sample_interval_to_next_packet = \
                        (next_packet_start - data_start) / data_num_samples

    def create_window(self) -&gt; &#39;DataWindow&#39;:
        &#34;&#34;&#34;
        constrain the data to the window specified by the parameters
        :return: only the data in the window specified by the parameters
        &#34;&#34;&#34;
        if self._has_time_window():
            new_data_window = self.copy()
            ids_to_pop = []
            # fill in gaps and truncate
            for station_id, station in new_data_window.stations.station_id_uuid_to_stations.items():
                # prepare a bunch of information to be used later
                if new_data_window.start_datetime:
                    start_timestamp = dtu.seconds_to_microseconds(
                        dtu.datetime_to_epoch_seconds_utc(new_data_window.start_datetime))
                else:
                    start_timestamp = station.audio_sensor().first_data_timestamp()
                if new_data_window.end_datetime:
                    end_timestamp = dtu.seconds_to_microseconds(
                        dtu.datetime_to_epoch_seconds_utc(new_data_window.end_datetime))
                else:
                    end_timestamp = station.audio_sensor().last_data_timestamp()
                # truncate packets to include only the ones with the data for the window
                station.packet_data = [p for p in station.packet_data
                                       if p.data_end_timestamp &gt; start_timestamp and
                                       p.data_start_timestamp &lt; end_timestamp]
                for sensor_type, sensor in station.station_data.items():
                    # TRUNCATE!  get only the timestamps between the start and end timestamps
                    df_timestamps = sensor.data_timestamps()
                    if len(df_timestamps) &lt; 1:
                        print(f&#34;WARNING: Data window for {station.station_metadata.station_id} {sensor_type.name} &#34;
                              f&#34;sensor has no data points!&#34;)
                        if sensor_type == SensorType.AUDIO:
                            ids_to_pop.append(station.station_metadata.station_id)
                        break
                    temp = np.where(
                        (start_timestamp &lt; df_timestamps) &amp; (df_timestamps &lt; end_timestamp))[0]
                    # oops, all the samples have been cut off
                    if len(temp) &lt; 1:
                        print(f&#34;WARNING: Data window for {station.station_metadata.station_id} {sensor_type.name} &#34;
                              f&#34;sensor has truncated all data points&#34;)
                        if sensor_type == SensorType.LOCATION:
                            # take the locations before the start_timestamp as valid locations
                            temp = np.where(df_timestamps &lt; end_timestamp)[0]
                            if len(temp) &lt; 1:
                                break
                            else:
                                print(f&#34;Using all {sensor_type.name} data points before {end_timestamp} instead&#34;)
                        else:
                            if sensor_type == SensorType.AUDIO:
                                ids_to_pop.append(station.station_metadata.station_id)
                            break
                    sensor.data_df = sensor.data_df.iloc[temp].reset_index(drop=True)
                    if sensor.is_sample_interval_invalid():
                        print(f&#34;WARNING: {sensor_type.name} has undefined sample interval and sample rate!&#34;)
                        break
                    # GAP FILL
                    sensor.data_df = gap_filler(sensor.data_df, sensor.sample_interval_s)
                    # PAD DATA
                    sensor.data_df = new_data_window.data_padder(sensor.data_df, sensor.sample_interval_s)
            # remove any station without audio sensor
            for ids in ids_to_pop:
                new_data_window.stations.pop_station(ids)
            return new_data_window
        else:
            return self


def gap_filler(data_df: pd.DataFrame, sample_interval_s: float,
               gap_duration_s: float = DEFAULT_GAP_TIME_S) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    fills gaps in the dataframe with np.nan by interpolating timestamps based on the mean expected sample interval
    :param data_df: dataframe with timestamps as column &#34;timestamps&#34;
    :param sample_interval_s: sample interval in seconds
    :param gap_duration_s: duration in seconds of minimum missing data to be considered a gap
    :return: dataframe without gaps
    &#34;&#34;&#34;
    # extract the necessary information to compute gap size and gap timestamps
    data_time_stamps = data_df.sort_values(&#34;timestamps&#34;, ignore_index=True)[&#34;timestamps&#34;].to_numpy()
    first_data_timestamp = data_time_stamps[0]
    last_data_timestamp = data_time_stamps[-1]
    data_duration_s = dtu.microseconds_to_seconds(last_data_timestamp - first_data_timestamp)
    num_points = len(data_time_stamps)
    # add one to calculation to include the last timestamp
    expected_num_points = int(data_duration_s / sample_interval_s) + 1
    # gap duration cannot be less than sample interval
    if gap_duration_s &lt; sample_interval_s:
        gap_duration_s = sample_interval_s
    result_df = data_df.copy()
    # if there are less points than our expected amount, we have gaps to fill
    if num_points &lt; expected_num_points:
        # if the data we&#39;re looking at is short enough, we can start comparing points
        if num_points &lt; 1000:
            # look at every timestamp except the last one
            for index in range(0, num_points - 1):
                # compare that timestamp to the next
                time_diff = dtu.microseconds_to_seconds(data_time_stamps[index + 1] - data_time_stamps[index])
                # calc samples to add, subtracting 1 to prevent copying last timestamp
                num_new_samples = int(time_diff / sample_interval_s) - 1
                if time_diff &gt; gap_duration_s and num_new_samples &gt; 0:
                    # add the gap data to the result dataframe
                    result_df = result_df.append(create_empty_df(data_time_stamps[index], sample_interval_s,
                                                                 data_df.columns, num_new_samples), ignore_index=True)
        else:
            # too many points to check, divide and conquer using recursion!
            half_samples = int(num_points / 2)
            first_data_df = data_df.iloc[:half_samples].copy().reset_index(drop=True)
            second_data_df = data_df.iloc[half_samples:].copy().reset_index(drop=True)
            # give half the samples to each recursive call
            first_data_df = gap_filler(first_data_df, sample_interval_s, gap_duration_s)
            second_data_df = gap_filler(second_data_df, sample_interval_s, gap_duration_s)
            result_df = first_data_df.append(second_data_df, ignore_index=True)
    return result_df.sort_values(&#34;timestamps&#34;, ignore_index=True)


def create_empty_df(start_timestamp: float, sample_interval_s: float, columns: pd.Index,
                    num_samples_to_add: int, add_to_start: bool = False) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Creates an empty dataframe with num_samples_to_add - 1 timestamps, using columns as the columns
    The one timestamp not being added would be a copy of the start timestamp.
    :param start_timestamp: timestamp to start calculating other timestamps from
    :param sample_interval_s: fixed sample interval in seconds
    :param columns: the non-timestamp columns of the dataframe
    :param num_samples_to_add: the number of timestamps to create
    :param add_to_start: if True, subtracts sample_interval_s from start_timestamp, default False
    :return:
    &#34;&#34;&#34;
    if add_to_start:
        sample_interval_s = -sample_interval_s
    new_timestamps = np.vectorize(lambda t: start_timestamp + dtu.seconds_to_microseconds(t * sample_interval_s))(
        list(range(1, num_samples_to_add + 1)))
    empty_df = pd.DataFrame([], columns=columns)
    for column_index in columns:
        if column_index == &#34;timestamps&#34;:
            empty_df[&#34;timestamps&#34;] = new_timestamps
        else:
            empty_df[column_index] = np.nan
    # return a dataframe with only timestamps
    return empty_df</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="redvox.common.data_window.create_empty_df"><code class="name flex">
<span>def <span class="ident">create_empty_df</span></span>(<span>start_timestamp: float, sample_interval_s: float, columns: pandas.core.indexes.base.Index, num_samples_to_add: int, add_to_start: bool = False) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Creates an empty dataframe with num_samples_to_add - 1 timestamps, using columns as the columns
The one timestamp not being added would be a copy of the start timestamp.
:param start_timestamp: timestamp to start calculating other timestamps from
:param sample_interval_s: fixed sample interval in seconds
:param columns: the non-timestamp columns of the dataframe
:param num_samples_to_add: the number of timestamps to create
:param add_to_start: if True, subtracts sample_interval_s from start_timestamp, default False
:return:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_empty_df(start_timestamp: float, sample_interval_s: float, columns: pd.Index,
                    num_samples_to_add: int, add_to_start: bool = False) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Creates an empty dataframe with num_samples_to_add - 1 timestamps, using columns as the columns
    The one timestamp not being added would be a copy of the start timestamp.
    :param start_timestamp: timestamp to start calculating other timestamps from
    :param sample_interval_s: fixed sample interval in seconds
    :param columns: the non-timestamp columns of the dataframe
    :param num_samples_to_add: the number of timestamps to create
    :param add_to_start: if True, subtracts sample_interval_s from start_timestamp, default False
    :return:
    &#34;&#34;&#34;
    if add_to_start:
        sample_interval_s = -sample_interval_s
    new_timestamps = np.vectorize(lambda t: start_timestamp + dtu.seconds_to_microseconds(t * sample_interval_s))(
        list(range(1, num_samples_to_add + 1)))
    empty_df = pd.DataFrame([], columns=columns)
    for column_index in columns:
        if column_index == &#34;timestamps&#34;:
            empty_df[&#34;timestamps&#34;] = new_timestamps
        else:
            empty_df[column_index] = np.nan
    # return a dataframe with only timestamps
    return empty_df</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.gap_filler"><code class="name flex">
<span>def <span class="ident">gap_filler</span></span>(<span>data_df: pandas.core.frame.DataFrame, sample_interval_s: float, gap_duration_s: float = 0.25) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>fills gaps in the dataframe with np.nan by interpolating timestamps based on the mean expected sample interval
:param data_df: dataframe with timestamps as column "timestamps"
:param sample_interval_s: sample interval in seconds
:param gap_duration_s: duration in seconds of minimum missing data to be considered a gap
:return: dataframe without gaps</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def gap_filler(data_df: pd.DataFrame, sample_interval_s: float,
               gap_duration_s: float = DEFAULT_GAP_TIME_S) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    fills gaps in the dataframe with np.nan by interpolating timestamps based on the mean expected sample interval
    :param data_df: dataframe with timestamps as column &#34;timestamps&#34;
    :param sample_interval_s: sample interval in seconds
    :param gap_duration_s: duration in seconds of minimum missing data to be considered a gap
    :return: dataframe without gaps
    &#34;&#34;&#34;
    # extract the necessary information to compute gap size and gap timestamps
    data_time_stamps = data_df.sort_values(&#34;timestamps&#34;, ignore_index=True)[&#34;timestamps&#34;].to_numpy()
    first_data_timestamp = data_time_stamps[0]
    last_data_timestamp = data_time_stamps[-1]
    data_duration_s = dtu.microseconds_to_seconds(last_data_timestamp - first_data_timestamp)
    num_points = len(data_time_stamps)
    # add one to calculation to include the last timestamp
    expected_num_points = int(data_duration_s / sample_interval_s) + 1
    # gap duration cannot be less than sample interval
    if gap_duration_s &lt; sample_interval_s:
        gap_duration_s = sample_interval_s
    result_df = data_df.copy()
    # if there are less points than our expected amount, we have gaps to fill
    if num_points &lt; expected_num_points:
        # if the data we&#39;re looking at is short enough, we can start comparing points
        if num_points &lt; 1000:
            # look at every timestamp except the last one
            for index in range(0, num_points - 1):
                # compare that timestamp to the next
                time_diff = dtu.microseconds_to_seconds(data_time_stamps[index + 1] - data_time_stamps[index])
                # calc samples to add, subtracting 1 to prevent copying last timestamp
                num_new_samples = int(time_diff / sample_interval_s) - 1
                if time_diff &gt; gap_duration_s and num_new_samples &gt; 0:
                    # add the gap data to the result dataframe
                    result_df = result_df.append(create_empty_df(data_time_stamps[index], sample_interval_s,
                                                                 data_df.columns, num_new_samples), ignore_index=True)
        else:
            # too many points to check, divide and conquer using recursion!
            half_samples = int(num_points / 2)
            first_data_df = data_df.iloc[:half_samples].copy().reset_index(drop=True)
            second_data_df = data_df.iloc[half_samples:].copy().reset_index(drop=True)
            # give half the samples to each recursive call
            first_data_df = gap_filler(first_data_df, sample_interval_s, gap_duration_s)
            second_data_df = gap_filler(second_data_df, sample_interval_s, gap_duration_s)
            result_df = first_data_df.append(second_data_df, ignore_index=True)
    return result_df.sort_values(&#34;timestamps&#34;, ignore_index=True)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="redvox.common.data_window.DataWindow"><code class="flex name class">
<span>class <span class="ident">DataWindow</span></span>
<span>(</span><span>input_directory: str, station_ids: typing.Union[typing.Set[str], NoneType] = None, start_datetime: typing.Union[datetime.datetime, NoneType] = None, end_datetime: typing.Union[datetime.datetime, NoneType] = None, start_padding_s: float = 120.0, end_padding_s: float = 120.0, gap_time_s: float = 0.25, apply_correction: bool = False, structured_layout: bool = False, stations: typing.Union[<a title="redvox.common.load_sensor_data.ReadResult" href="load_sensor_data.html#redvox.common.load_sensor_data.ReadResult">ReadResult</a>, NoneType] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Holds the data for a given time window; adds interpolated timestamps to fill gaps and pad start and end values</p>
<h2 id="properties">Properties</h2>
<p>input_directory: string, directory that contains the files to read data from.
REQUIRED
station_ids: optional set of strings, list of station ids to filter on.
If empty or None, get any ids found in the input directory.
Default None
start_datetime: optional datetime, start datetime of the window.
If None, uses the first timestamp of the filtered data.
Default None
end_datetime: optional datetime, end datetime of the window.
If None, uses the last timestamp of the filtered data.
Default None
start_padding_s: float, the amount of seconds to include before the start_datetime
when filtering data.
Default DEFAULT_START_PADDING_S
end_padding_s: float, the amount of seconds to include after the end_datetime
when filtering data.
Default DEFAULT_END_PADDING_S
gap_time_s: float, the minimum amount of seconds between data points that would indicate a gap.
Default DEFAULT_GAP_TIME_S
apply_correction: bool, if True, update the timestamps in the data based on best station offset.
Default False
structured_layout: bool, if True, the input_directory contains specially named and organized
directories of data.
Default False
stations: optional ReadResult, the results of reading the data from input_directory</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DataWindow:
    &#34;&#34;&#34;
    Holds the data for a given time window; adds interpolated timestamps to fill gaps and pad start and end values
    Properties:
        input_directory: string, directory that contains the files to read data from.  REQUIRED
        station_ids: optional set of strings, list of station ids to filter on.
                        If empty or None, get any ids found in the input directory.  Default None
        start_datetime: optional datetime, start datetime of the window.
                        If None, uses the first timestamp of the filtered data.  Default None
        end_datetime: optional datetime, end datetime of the window.
                        If None, uses the last timestamp of the filtered data.  Default None
        start_padding_s: float, the amount of seconds to include before the start_datetime
                            when filtering data.  Default DEFAULT_START_PADDING_S
        end_padding_s: float, the amount of seconds to include after the end_datetime
                        when filtering data.  Default DEFAULT_END_PADDING_S
        gap_time_s: float, the minimum amount of seconds between data points that would indicate a gap.
                    Default DEFAULT_GAP_TIME_S
        apply_correction: bool, if True, update the timestamps in the data based on best station offset.  Default False
        structured_layout: bool, if True, the input_directory contains specially named and organized
                            directories of data.  Default False
        stations: optional ReadResult, the results of reading the data from input_directory
    &#34;&#34;&#34;
    input_directory: str
    station_ids: Optional[Set[str]] = None
    start_datetime: Optional[dtu.datetime] = None
    end_datetime: Optional[dtu.datetime] = None
    start_padding_s: float = DEFAULT_START_PADDING_S
    end_padding_s: float = DEFAULT_END_PADDING_S
    gap_time_s: float = DEFAULT_GAP_TIME_S
    apply_correction: bool = False
    structured_layout: bool = False
    stations: Optional[ReadResult] = None

    def __post_init__(self):
        &#34;&#34;&#34;
        loads the data after initialization
        &#34;&#34;&#34;
        if self.stations is None:
            self.read_data()

    def copy(self) -&gt; &#39;DataWindow&#39;:
        &#34;&#34;&#34;
        :return: a copy of the DataWindow
        &#34;&#34;&#34;
        return DataWindow(self.input_directory, self.station_ids, self.start_datetime, self.end_datetime,
                          self.start_padding_s, self.end_padding_s, self.gap_time_s,
                          self.apply_correction, self.structured_layout, self.stations)

    def _has_time_window(self) -&gt; bool:
        &#34;&#34;&#34;
        Returns true if there is a start or end datetime in the settings
        :return: True if start_datetime or end_datetime exists
        &#34;&#34;&#34;
        return self.start_datetime is not None or self.end_datetime is not None

    def _pad_start_datetime_s(self) -&gt; float:
        &#34;&#34;&#34;
        apply padding to the start datetime
        :return: padded start datetime as seconds since epoch UTC
        &#34;&#34;&#34;
        return dtu.datetime_to_epoch_seconds_utc(self.start_datetime) - self.start_padding_s

    def _pad_end_datetime_s(self) -&gt; float:
        &#34;&#34;&#34;
        apply padding to the end datetime
        :return: padded end datetime as seconds since epoch UTC
        &#34;&#34;&#34;
        return dtu.datetime_to_epoch_seconds_utc(self.end_datetime) + self.end_padding_s

    def correct_timestamps(self):
        &#34;&#34;&#34;
        update the timestamps in all stations
        &#34;&#34;&#34;
        for station in self.stations.station_id_uuid_to_stations.values():
            if self.apply_correction:
                station.update_timestamps()

    def data_padder(self, data_df: pd.DataFrame, sample_interval_s: float) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        Pad the start and end of the dataframe with np.nan
        :param data_df: dataframe with timestamps as column &#34;timestamps&#34;
        :param sample_interval_s: constant sample interval in seconds
        :return: dataframe padded with np.nans in front and back to meet full size of expected start and end
        &#34;&#34;&#34;
        # extract the necessary information to pad the data
        data_time_stamps = data_df.sort_values(&#34;timestamps&#34;)[&#34;timestamps&#34;].to_numpy()
        first_data_timestamp = data_time_stamps[0]
        last_data_timestamp = data_time_stamps[-1]
        expected_start = dtu.datetime_to_epoch_microseconds_utc(self.start_datetime)
        expected_end = dtu.datetime_to_epoch_microseconds_utc(self.end_datetime)
        result_df = data_df.copy()
        # FRONT/END GAP FILL!  calculate the audio samples missing based on inputs
        if expected_start &lt; first_data_timestamp:
            start_diff = first_data_timestamp - expected_start
            num_missing_samples = int(dtu.microseconds_to_seconds(start_diff) / sample_interval_s) + 1
            # add the gap data to the result dataframe
            result_df = result_df.append(create_empty_df(expected_start -
                                                         dtu.seconds_to_microseconds(sample_interval_s),
                                                         sample_interval_s, data_df.columns,
                                                         num_missing_samples), ignore_index=True)
        if expected_end &gt; last_data_timestamp:
            last_diff = expected_end - last_data_timestamp
            num_missing_samples = int(dtu.microseconds_to_seconds(last_diff) / sample_interval_s) + 1
            # add the gap data to the result dataframe
            result_df = result_df.append(create_empty_df(expected_end +
                                                         dtu.seconds_to_microseconds(sample_interval_s),
                                                         sample_interval_s, data_df.columns,
                                                         num_missing_samples, True), ignore_index=True)
        return result_df.sort_values(&#34;timestamps&#34;, ignore_index=True)

    def read_data(self):
        &#34;&#34;&#34;
        read data using the properties of the class
        &#34;&#34;&#34;
        start_time = int(self._pad_start_datetime_s()) if self.start_datetime else None
        end_time = int(self._pad_end_datetime_s()) if self.end_datetime else None
        self.stations = read_all_in_dir(self.input_directory, start_time, end_time,
                                        self.station_ids, self.structured_layout)

        ids_to_pop = []
        # check if ids in station data from files
        for ids in self.station_ids:
            if not self.stations.check_for_id(ids):
                # error handling
                print(f&#34;WARNING: {ids} doesn&#39;t have any data to read&#34;)
            elif not self.stations.get_station(ids).has_audio_data():
                # no audio data is about the same as no data
                print(f&#34;WARNING: {ids} doesn&#39;t have any audio data to read&#34;)
                ids_to_pop.append(ids)
        for ids in ids_to_pop:
            self.stations.pop_station(ids)
        # calculate time differences in audio samples
        for station in self.stations.get_all_stations():
            # apply time correction
            if self.apply_correction:
                station.update_timestamps()
            for packet in range(len(station.packet_data) - 1):
                data_start = station.packet_data[packet].data_start_timestamp
                data_num_samples = station.packet_data[packet].packet_num_audio_samples
                next_packet_start_index = \
                    station.audio_sensor().data_df.query(&#34;timestamps == @data_start&#34;).first_valid_index() + \
                    data_num_samples
                data_end = station.audio_sensor().data_timestamps()[next_packet_start_index - 1]
                next_packet_start = station.audio_sensor().data_timestamps()[next_packet_start_index]
                if next_packet_start - data_end &lt; dtu.seconds_to_microseconds(self.gap_time_s):
                    station.packet_data[packet].sample_interval_to_next_packet = \
                        (next_packet_start - data_start) / data_num_samples

    def create_window(self) -&gt; &#39;DataWindow&#39;:
        &#34;&#34;&#34;
        constrain the data to the window specified by the parameters
        :return: only the data in the window specified by the parameters
        &#34;&#34;&#34;
        if self._has_time_window():
            new_data_window = self.copy()
            ids_to_pop = []
            # fill in gaps and truncate
            for station_id, station in new_data_window.stations.station_id_uuid_to_stations.items():
                # prepare a bunch of information to be used later
                if new_data_window.start_datetime:
                    start_timestamp = dtu.seconds_to_microseconds(
                        dtu.datetime_to_epoch_seconds_utc(new_data_window.start_datetime))
                else:
                    start_timestamp = station.audio_sensor().first_data_timestamp()
                if new_data_window.end_datetime:
                    end_timestamp = dtu.seconds_to_microseconds(
                        dtu.datetime_to_epoch_seconds_utc(new_data_window.end_datetime))
                else:
                    end_timestamp = station.audio_sensor().last_data_timestamp()
                # truncate packets to include only the ones with the data for the window
                station.packet_data = [p for p in station.packet_data
                                       if p.data_end_timestamp &gt; start_timestamp and
                                       p.data_start_timestamp &lt; end_timestamp]
                for sensor_type, sensor in station.station_data.items():
                    # TRUNCATE!  get only the timestamps between the start and end timestamps
                    df_timestamps = sensor.data_timestamps()
                    if len(df_timestamps) &lt; 1:
                        print(f&#34;WARNING: Data window for {station.station_metadata.station_id} {sensor_type.name} &#34;
                              f&#34;sensor has no data points!&#34;)
                        if sensor_type == SensorType.AUDIO:
                            ids_to_pop.append(station.station_metadata.station_id)
                        break
                    temp = np.where(
                        (start_timestamp &lt; df_timestamps) &amp; (df_timestamps &lt; end_timestamp))[0]
                    # oops, all the samples have been cut off
                    if len(temp) &lt; 1:
                        print(f&#34;WARNING: Data window for {station.station_metadata.station_id} {sensor_type.name} &#34;
                              f&#34;sensor has truncated all data points&#34;)
                        if sensor_type == SensorType.LOCATION:
                            # take the locations before the start_timestamp as valid locations
                            temp = np.where(df_timestamps &lt; end_timestamp)[0]
                            if len(temp) &lt; 1:
                                break
                            else:
                                print(f&#34;Using all {sensor_type.name} data points before {end_timestamp} instead&#34;)
                        else:
                            if sensor_type == SensorType.AUDIO:
                                ids_to_pop.append(station.station_metadata.station_id)
                            break
                    sensor.data_df = sensor.data_df.iloc[temp].reset_index(drop=True)
                    if sensor.is_sample_interval_invalid():
                        print(f&#34;WARNING: {sensor_type.name} has undefined sample interval and sample rate!&#34;)
                        break
                    # GAP FILL
                    sensor.data_df = gap_filler(sensor.data_df, sensor.sample_interval_s)
                    # PAD DATA
                    sensor.data_df = new_data_window.data_padder(sensor.data_df, sensor.sample_interval_s)
            # remove any station without audio sensor
            for ids in ids_to_pop:
                new_data_window.stations.pop_station(ids)
            return new_data_window
        else:
            return self</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="redvox.common.data_window.DataWindow.apply_correction"><code class="name">var <span class="ident">apply_correction</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="redvox.common.data_window.DataWindow.end_datetime"><code class="name">var <span class="ident">end_datetime</span> : typing.Union[datetime.datetime, NoneType]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="redvox.common.data_window.DataWindow.end_padding_s"><code class="name">var <span class="ident">end_padding_s</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="redvox.common.data_window.DataWindow.gap_time_s"><code class="name">var <span class="ident">gap_time_s</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="redvox.common.data_window.DataWindow.input_directory"><code class="name">var <span class="ident">input_directory</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="redvox.common.data_window.DataWindow.start_datetime"><code class="name">var <span class="ident">start_datetime</span> : typing.Union[datetime.datetime, NoneType]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="redvox.common.data_window.DataWindow.start_padding_s"><code class="name">var <span class="ident">start_padding_s</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="redvox.common.data_window.DataWindow.station_ids"><code class="name">var <span class="ident">station_ids</span> : typing.Union[typing.Set[str], NoneType]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="redvox.common.data_window.DataWindow.stations"><code class="name">var <span class="ident">stations</span> : typing.Union[<a title="redvox.common.load_sensor_data.ReadResult" href="load_sensor_data.html#redvox.common.load_sensor_data.ReadResult">ReadResult</a>, NoneType]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="redvox.common.data_window.DataWindow.structured_layout"><code class="name">var <span class="ident">structured_layout</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="redvox.common.data_window.DataWindow.copy"><code class="name flex">
<span>def <span class="ident">copy</span></span>(<span>self) ‑> <a title="redvox.common.data_window.DataWindow" href="#redvox.common.data_window.DataWindow">DataWindow</a></span>
</code></dt>
<dd>
<div class="desc"><p>:return: a copy of the DataWindow</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def copy(self) -&gt; &#39;DataWindow&#39;:
    &#34;&#34;&#34;
    :return: a copy of the DataWindow
    &#34;&#34;&#34;
    return DataWindow(self.input_directory, self.station_ids, self.start_datetime, self.end_datetime,
                      self.start_padding_s, self.end_padding_s, self.gap_time_s,
                      self.apply_correction, self.structured_layout, self.stations)</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.correct_timestamps"><code class="name flex">
<span>def <span class="ident">correct_timestamps</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>update the timestamps in all stations</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def correct_timestamps(self):
    &#34;&#34;&#34;
    update the timestamps in all stations
    &#34;&#34;&#34;
    for station in self.stations.station_id_uuid_to_stations.values():
        if self.apply_correction:
            station.update_timestamps()</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.create_window"><code class="name flex">
<span>def <span class="ident">create_window</span></span>(<span>self) ‑> <a title="redvox.common.data_window.DataWindow" href="#redvox.common.data_window.DataWindow">DataWindow</a></span>
</code></dt>
<dd>
<div class="desc"><p>constrain the data to the window specified by the parameters
:return: only the data in the window specified by the parameters</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_window(self) -&gt; &#39;DataWindow&#39;:
    &#34;&#34;&#34;
    constrain the data to the window specified by the parameters
    :return: only the data in the window specified by the parameters
    &#34;&#34;&#34;
    if self._has_time_window():
        new_data_window = self.copy()
        ids_to_pop = []
        # fill in gaps and truncate
        for station_id, station in new_data_window.stations.station_id_uuid_to_stations.items():
            # prepare a bunch of information to be used later
            if new_data_window.start_datetime:
                start_timestamp = dtu.seconds_to_microseconds(
                    dtu.datetime_to_epoch_seconds_utc(new_data_window.start_datetime))
            else:
                start_timestamp = station.audio_sensor().first_data_timestamp()
            if new_data_window.end_datetime:
                end_timestamp = dtu.seconds_to_microseconds(
                    dtu.datetime_to_epoch_seconds_utc(new_data_window.end_datetime))
            else:
                end_timestamp = station.audio_sensor().last_data_timestamp()
            # truncate packets to include only the ones with the data for the window
            station.packet_data = [p for p in station.packet_data
                                   if p.data_end_timestamp &gt; start_timestamp and
                                   p.data_start_timestamp &lt; end_timestamp]
            for sensor_type, sensor in station.station_data.items():
                # TRUNCATE!  get only the timestamps between the start and end timestamps
                df_timestamps = sensor.data_timestamps()
                if len(df_timestamps) &lt; 1:
                    print(f&#34;WARNING: Data window for {station.station_metadata.station_id} {sensor_type.name} &#34;
                          f&#34;sensor has no data points!&#34;)
                    if sensor_type == SensorType.AUDIO:
                        ids_to_pop.append(station.station_metadata.station_id)
                    break
                temp = np.where(
                    (start_timestamp &lt; df_timestamps) &amp; (df_timestamps &lt; end_timestamp))[0]
                # oops, all the samples have been cut off
                if len(temp) &lt; 1:
                    print(f&#34;WARNING: Data window for {station.station_metadata.station_id} {sensor_type.name} &#34;
                          f&#34;sensor has truncated all data points&#34;)
                    if sensor_type == SensorType.LOCATION:
                        # take the locations before the start_timestamp as valid locations
                        temp = np.where(df_timestamps &lt; end_timestamp)[0]
                        if len(temp) &lt; 1:
                            break
                        else:
                            print(f&#34;Using all {sensor_type.name} data points before {end_timestamp} instead&#34;)
                    else:
                        if sensor_type == SensorType.AUDIO:
                            ids_to_pop.append(station.station_metadata.station_id)
                        break
                sensor.data_df = sensor.data_df.iloc[temp].reset_index(drop=True)
                if sensor.is_sample_interval_invalid():
                    print(f&#34;WARNING: {sensor_type.name} has undefined sample interval and sample rate!&#34;)
                    break
                # GAP FILL
                sensor.data_df = gap_filler(sensor.data_df, sensor.sample_interval_s)
                # PAD DATA
                sensor.data_df = new_data_window.data_padder(sensor.data_df, sensor.sample_interval_s)
        # remove any station without audio sensor
        for ids in ids_to_pop:
            new_data_window.stations.pop_station(ids)
        return new_data_window
    else:
        return self</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.data_padder"><code class="name flex">
<span>def <span class="ident">data_padder</span></span>(<span>self, data_df: pandas.core.frame.DataFrame, sample_interval_s: float) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Pad the start and end of the dataframe with np.nan
:param data_df: dataframe with timestamps as column "timestamps"
:param sample_interval_s: constant sample interval in seconds
:return: dataframe padded with np.nans in front and back to meet full size of expected start and end</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def data_padder(self, data_df: pd.DataFrame, sample_interval_s: float) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Pad the start and end of the dataframe with np.nan
    :param data_df: dataframe with timestamps as column &#34;timestamps&#34;
    :param sample_interval_s: constant sample interval in seconds
    :return: dataframe padded with np.nans in front and back to meet full size of expected start and end
    &#34;&#34;&#34;
    # extract the necessary information to pad the data
    data_time_stamps = data_df.sort_values(&#34;timestamps&#34;)[&#34;timestamps&#34;].to_numpy()
    first_data_timestamp = data_time_stamps[0]
    last_data_timestamp = data_time_stamps[-1]
    expected_start = dtu.datetime_to_epoch_microseconds_utc(self.start_datetime)
    expected_end = dtu.datetime_to_epoch_microseconds_utc(self.end_datetime)
    result_df = data_df.copy()
    # FRONT/END GAP FILL!  calculate the audio samples missing based on inputs
    if expected_start &lt; first_data_timestamp:
        start_diff = first_data_timestamp - expected_start
        num_missing_samples = int(dtu.microseconds_to_seconds(start_diff) / sample_interval_s) + 1
        # add the gap data to the result dataframe
        result_df = result_df.append(create_empty_df(expected_start -
                                                     dtu.seconds_to_microseconds(sample_interval_s),
                                                     sample_interval_s, data_df.columns,
                                                     num_missing_samples), ignore_index=True)
    if expected_end &gt; last_data_timestamp:
        last_diff = expected_end - last_data_timestamp
        num_missing_samples = int(dtu.microseconds_to_seconds(last_diff) / sample_interval_s) + 1
        # add the gap data to the result dataframe
        result_df = result_df.append(create_empty_df(expected_end +
                                                     dtu.seconds_to_microseconds(sample_interval_s),
                                                     sample_interval_s, data_df.columns,
                                                     num_missing_samples, True), ignore_index=True)
    return result_df.sort_values(&#34;timestamps&#34;, ignore_index=True)</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.read_data"><code class="name flex">
<span>def <span class="ident">read_data</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>read data using the properties of the class</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_data(self):
    &#34;&#34;&#34;
    read data using the properties of the class
    &#34;&#34;&#34;
    start_time = int(self._pad_start_datetime_s()) if self.start_datetime else None
    end_time = int(self._pad_end_datetime_s()) if self.end_datetime else None
    self.stations = read_all_in_dir(self.input_directory, start_time, end_time,
                                    self.station_ids, self.structured_layout)

    ids_to_pop = []
    # check if ids in station data from files
    for ids in self.station_ids:
        if not self.stations.check_for_id(ids):
            # error handling
            print(f&#34;WARNING: {ids} doesn&#39;t have any data to read&#34;)
        elif not self.stations.get_station(ids).has_audio_data():
            # no audio data is about the same as no data
            print(f&#34;WARNING: {ids} doesn&#39;t have any audio data to read&#34;)
            ids_to_pop.append(ids)
    for ids in ids_to_pop:
        self.stations.pop_station(ids)
    # calculate time differences in audio samples
    for station in self.stations.get_all_stations():
        # apply time correction
        if self.apply_correction:
            station.update_timestamps()
        for packet in range(len(station.packet_data) - 1):
            data_start = station.packet_data[packet].data_start_timestamp
            data_num_samples = station.packet_data[packet].packet_num_audio_samples
            next_packet_start_index = \
                station.audio_sensor().data_df.query(&#34;timestamps == @data_start&#34;).first_valid_index() + \
                data_num_samples
            data_end = station.audio_sensor().data_timestamps()[next_packet_start_index - 1]
            next_packet_start = station.audio_sensor().data_timestamps()[next_packet_start_index]
            if next_packet_start - data_end &lt; dtu.seconds_to_microseconds(self.gap_time_s):
                station.packet_data[packet].sample_interval_to_next_packet = \
                    (next_packet_start - data_start) / data_num_samples</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="redvox.common" href="index.html">redvox.common</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="redvox.common.data_window.create_empty_df" href="#redvox.common.data_window.create_empty_df">create_empty_df</a></code></li>
<li><code><a title="redvox.common.data_window.gap_filler" href="#redvox.common.data_window.gap_filler">gap_filler</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="redvox.common.data_window.DataWindow" href="#redvox.common.data_window.DataWindow">DataWindow</a></code></h4>
<ul class="two-column">
<li><code><a title="redvox.common.data_window.DataWindow.apply_correction" href="#redvox.common.data_window.DataWindow.apply_correction">apply_correction</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.copy" href="#redvox.common.data_window.DataWindow.copy">copy</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.correct_timestamps" href="#redvox.common.data_window.DataWindow.correct_timestamps">correct_timestamps</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.create_window" href="#redvox.common.data_window.DataWindow.create_window">create_window</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.data_padder" href="#redvox.common.data_window.DataWindow.data_padder">data_padder</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.end_datetime" href="#redvox.common.data_window.DataWindow.end_datetime">end_datetime</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.end_padding_s" href="#redvox.common.data_window.DataWindow.end_padding_s">end_padding_s</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.gap_time_s" href="#redvox.common.data_window.DataWindow.gap_time_s">gap_time_s</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.input_directory" href="#redvox.common.data_window.DataWindow.input_directory">input_directory</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.read_data" href="#redvox.common.data_window.DataWindow.read_data">read_data</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.start_datetime" href="#redvox.common.data_window.DataWindow.start_datetime">start_datetime</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.start_padding_s" href="#redvox.common.data_window.DataWindow.start_padding_s">start_padding_s</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.station_ids" href="#redvox.common.data_window.DataWindow.station_ids">station_ids</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.stations" href="#redvox.common.data_window.DataWindow.stations">stations</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.structured_layout" href="#redvox.common.data_window.DataWindow.structured_layout">structured_layout</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.1</a>.</p>
</footer>
</body>
</html>