<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>redvox.common.data_window API documentation</title>
<meta name="description" content="This module creates specific time-bounded segments of data for users
combine the data packets into a new data packet based on the user parameters" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>redvox.common.data_window</code></h1>
</header>
<section id="section-intro">
<p>This module creates specific time-bounded segments of data for users
combine the data packets into a new data packet based on the user parameters</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
This module creates specific time-bounded segments of data for users
combine the data packets into a new data packet based on the user parameters
&#34;&#34;&#34;
from typing import Optional, Set, List, Dict, Iterable
from datetime import timedelta

import pandas as pd
import numpy as np

from redvox.common import date_time_utils as dtu
from redvox.common import io
from redvox.common.station import Station
from redvox.common.sensor_data import SensorType, SensorData
from redvox.common.api_reader import ApiReader
from redvox.common.data_window_configuration import DataWindowConfig
import redvox.common.parallel_utils as parallel
from redvox.api1000.wrapped_redvox_packet.sensors.location import LocationProvider
from redvox.api1000.wrapped_redvox_packet.sensors.image import ImageCodec


DEFAULT_GAP_TIME_S: float = 0.25  # default length of a gap in seconds
DEFAULT_START_BUFFER_TD: timedelta = timedelta(minutes=2.0)  # default padding to start time of data
DEFAULT_END_BUFFER_TD: timedelta = timedelta(minutes=2.0)    # default padding to end time of data
# default maximum number of points required to brute force calculate gap timestamps
DEFAULT_MAX_BRUTE_FORCE_GAP_TIMESTAMPS: int = 5000


class DataWindow:
    &#34;&#34;&#34;
    Holds the data for a given time window; adds interpolated timestamps to fill gaps and pad start and end values
    Properties:
        input_directory: string, directory that contains the files to read data from.  REQUIRED
        structured_layout: bool, if True, the input_directory contains specially named and organized
                            directories of data.  Default True
        station_ids: optional set of strings, representing the station ids to filter on.
                        If empty or None, get any ids found in the input directory.  Default None
        extensions: optional set of strings, representing file extensions to filter on.
                        If None, gets as much data as it can in the input directory.  Default None
        api_versions: optional set of ApiVersions, representing api versions to filter on.
                        If None, get as much data as it can in the input directory.  Default None
        start_datetime: optional datetime, start datetime of the window.
                        If None, uses the first timestamp of the filtered data.  Default None
        end_datetime: optional datetime, end datetime of the window.
                        If None, uses the last timestamp of the filtered data.  Default None
        start_buffer_td: timedelta, the amount of time to include before the start_datetime when filtering data.
                            Default DEFAULT_START_BUFFER_TD
        end_buffer_td: float, the amount of time to include after the end_datetime when filtering data.
                            Default DEFAULT_END_BUFFER_TD
        gap_time_s: float, the minimum amount of seconds between data points that would indicate a gap.
                    Default DEFAULT_GAP_TIME_S
        apply_correction: bool, if True, update the timestamps in the data based on best station offset.  Default True
        stations: dictionary of Id:Station, the results of reading the data from input_directory
        debug: bool, if True, outputs additional information during initialization. Default False
    &#34;&#34;&#34;

    def __init__(
        self,
        input_dir: str,
        structured_layout: bool = True,
        start_datetime: Optional[dtu.datetime] = None,
        end_datetime: Optional[dtu.datetime] = None,
        start_buffer_td: timedelta = DEFAULT_START_BUFFER_TD,
        end_buffer_td: timedelta = DEFAULT_END_BUFFER_TD,
        gap_time_s: float = DEFAULT_GAP_TIME_S,
        station_ids: Optional[Iterable[str]] = None,
        extensions: Optional[Set[str]] = None,
        api_versions: Optional[Set[io.ApiVersion]] = None,
        apply_correction: bool = True,
        debug: bool = False,
    ):
        &#34;&#34;&#34;
        initialize the data window with params
        :param input_dir: string, directory that contains the files to read data from
        :param structured_layout: bool, if True, the input_directory contains specially named and organized
                                    directories of data.  Default True
        :param start_datetime: optional start datetime of the window. If None, uses the first timestamp of the
                                filtered data. Default None
        :param end_datetime: optional end datetime of the window. If None, uses the last timestamp of the filtered
                                data.  Default None
        :param start_buffer_td: the amount of time to include before the start_datetime when filtering data.
                                Default DEFAULT_START_BUFFER_TD
        :param end_buffer_td: the amount of time to include after the end_datetime when filtering data.
                                Default DEFAULT_END_BUFFER_TD
        :param gap_time_s: the minimum amount of seconds between data points that would indicate a gap.
                            Default DEFAULT_GAP_TIME_S
        :param station_ids: optional iterable of station ids to filter on. If empty or None, get any ids found in the
                            input directory.  Default None
        :param extensions: optional set of file extensions to filter on.  If None, get all data in the input directory.
                            Default None
        :param api_versions: optional set of api versions to filter on.  If None, get all data in the input directory.
                                Default None
        :param apply_correction: if True, update the timestamps in the data based on best station offset.
                                    Default True
        :param debug: bool, if True, outputs warnings and additional information, default False
        &#34;&#34;&#34;

        self.input_directory: str = input_dir
        self.structured_layout: bool = structured_layout
        self.start_datetime: Optional[dtu.datetime] = start_datetime
        self.end_datetime: Optional[dtu.datetime] = end_datetime
        self.start_buffer_td: timedelta = start_buffer_td
        self.end_buffer_td: timedelta = end_buffer_td
        self.gap_time_s: float = gap_time_s
        self.station_ids: Optional[Set[str]]
        if station_ids:
            self.station_ids = set(station_ids)
        else:
            self.station_ids = None
        self.extensions: Optional[Set[str]] = extensions
        self.api_versions: Optional[Set[io.ApiVersion]] = api_versions
        self.apply_correction: bool = apply_correction
        self.debug: bool = debug
        self.stations: Dict[str, Station] = {}
        self.create_data_window()

    @staticmethod
    def from_config_file(file: str) -&gt; &#34;DataWindow&#34;:
        &#34;&#34;&#34;
        Loads a configuration file to create the DataWindow
        :param file: full path to config file
        :return: a data window
        &#34;&#34;&#34;
        return DataWindow.from_config(DataWindowConfig.from_path(file))

    @staticmethod
    def from_config(config: DataWindowConfig) -&gt; &#34;DataWindow&#34;:
        &#34;&#34;&#34;
        Loads a configuration to create the DataWindow
        :param config: DataWindow configuration object
        :return: a data window
        &#34;&#34;&#34;
        if config.start_year:
            start_time = dtu.datetime(
                year=config.start_year,
                month=config.start_month,
                day=config.start_day,
                hour=config.start_hour,
                minute=config.start_minute,
                second=config.start_second,
            )
        else:
            start_time = None
        if config.end_year:
            end_time = dtu.datetime(
                year=config.end_year,
                month=config.end_month,
                day=config.end_day,
                hour=config.end_hour,
                minute=config.end_minute,
                second=config.end_second,
            )
        else:
            end_time = None
        if config.api_versions:
            api_versions = set([io.ApiVersion.from_str(v) for v in config.api_versions])
        else:
            api_versions = None
        if config.extensions:
            extensions = set(config.extensions)
        else:
            extensions = None
        if config.station_ids:
            station_ids = set(config.station_ids)
        else:
            station_ids = None
        return DataWindow(
            config.input_directory,
            config.structured_layout,
            start_time,
            end_time,
            dtu.timedelta(seconds=config.start_padding_seconds),
            dtu.timedelta(seconds=config.end_padding_seconds),
            config.gap_time_seconds,
            station_ids,
            extensions,
            api_versions,
            config.apply_correction,
            config.debug,
        )

    def _has_time_window(self) -&gt; bool:
        &#34;&#34;&#34;
        Returns true if there is a start or end datetime in the settings
        :return: True if start_datetime or end_datetime exists
        &#34;&#34;&#34;
        return self.start_datetime is not None or self.end_datetime is not None

    def get_station(self, station_id: str) -&gt; Optional[Station]:
        &#34;&#34;&#34;
        Get a single station from the data window
        :param station_id: the id of the station to get
        :return: A single station or None if the station cannot be found
        &#34;&#34;&#34;
        if station_id in self.stations.keys():
            return self.stations[station_id]
        if self.debug:
            print(f&#34;Warning: Attempted to get station {station_id}, but that station is not in this data window!&#34;)
        return None

    def get_all_stations(self) -&gt; List[Station]:
        &#34;&#34;&#34;
        :return: all stations in the data window as a list
        &#34;&#34;&#34;
        return list(self.stations.values())

    def get_all_station_ids(self) -&gt; List[str]:
        &#34;&#34;&#34;
        :return: A list of all station ids with data
        &#34;&#34;&#34;
        return list(self.stations.keys())

    def check_valid_ids(self):
        &#34;&#34;&#34;
        searches the data window station_ids for any ids not in the data collected
        outputs a message for each id requested but has no data
        &#34;&#34;&#34;
        for ids in self.station_ids:
            if ids not in self.stations.keys() and self.debug:
                print(
                    f&#34;WARNING: Requested {ids} but there is no data to read for that station&#34;
                )

    def process_sensor(self, sensor: SensorData, station_id: str, start_date_timestamp: float,
                       end_date_timestamp: float):
        # calculate the sensor&#39;s sample interval, std sample interval and sample rate of all data
        sensor.organize_and_update_stats()
        # get only the timestamps between the start and end timestamps
        df_timestamps = sensor.data_timestamps()
        if len(df_timestamps) &gt; 0:
            window_indices = np.where(
                (start_date_timestamp &lt;= df_timestamps)
                &amp; (df_timestamps &lt;= end_date_timestamp)
            )[0]
            # check if all the samples have been cut off
            if len(window_indices) &lt; 1:
                if any(df_timestamps &lt; start_date_timestamp):
                    last_before_start = np.argwhere(df_timestamps &lt; start_date_timestamp)[-1][0]
                else:
                    last_before_start = None
                if any(df_timestamps &gt; end_date_timestamp):
                    first_after_end = np.argwhere(df_timestamps &gt; end_date_timestamp)[0][0]
                else:
                    first_after_end = None
                if last_before_start is not None and first_after_end is None:
                    sensor.data_df = sensor.data_df.iloc[last_before_start].to_frame().T
                    sensor.data_df[&#34;timestamps&#34;] = start_date_timestamp
                elif last_before_start is None and first_after_end is not None:
                    sensor.data_df = sensor.data_df.iloc[first_after_end].to_frame().T
                    sensor.data_df[&#34;timestamps&#34;] = end_date_timestamp
                elif last_before_start is not None and first_after_end is not None:
                    sensor.data_df = sensor.interpolate(last_before_start, first_after_end,
                                                        start_date_timestamp).to_frame().T
                elif self.debug:
                    print(
                        f&#34;WARNING: Data window for {station_id} {sensor.type.name} &#34;
                        f&#34;sensor has truncated all data points&#34;
                    )
            else:
                sensor.data_df = sensor.data_df.iloc[window_indices].reset_index(
                    drop=True
                )
                if sensor.is_sample_interval_invalid():
                    if self.debug:
                        print(
                            f&#34;WARNING: Cannot fill gaps or pad {station_id} {sensor.type.name} &#34;
                            f&#34;sensor; it has undefined sample interval and sample rate!&#34;
                        )
                else:  # GAP FILL and PAD DATA
                    sample_interval_micros = dtu.seconds_to_microseconds(sensor.sample_interval_s)
                    sensor.data_df = fill_gaps(
                        sensor.data_df,
                        sample_interval_micros + dtu.seconds_to_microseconds(sensor.sample_interval_std_s),
                        dtu.seconds_to_microseconds(self.gap_time_s),
                        DEFAULT_MAX_BRUTE_FORCE_GAP_TIMESTAMPS,
                        )
                    sensor.data_df = pad_data(
                        start_date_timestamp,
                        end_date_timestamp,
                        sensor.data_df,
                        sample_interval_micros,
                    )
        elif self.debug:
            print(f&#34;WARNING: Data window for {station_id} {sensor.type.name} sensor has no data points!&#34;)

    def create_window_in_sensors(
        self, station: Station, start_date_timestamp: float, end_date_timestamp: float
    ):
        &#34;&#34;&#34;
        truncate the sensors in the station to only contain data from start_date_timestamp to end_date_timestamp
        returns nothing, updates the station in place
        :param station: station object to truncate sensors of
        :param start_date_timestamp: timestamp in microseconds since epoch UTC of start of window
        :param end_date_timestamp: timestamp in microseconds since epoch UTC of end of window
        &#34;&#34;&#34;
        self.process_sensor(station.audio_sensor(), station.id, start_date_timestamp, end_date_timestamp)
        for sensor_type, sensor in station.data.items():
            if sensor_type != SensorType.AUDIO:
                self.process_sensor(sensor, station.id, station.audio_sensor().first_data_timestamp(),
                                    station.audio_sensor().last_data_timestamp())
        # recalculate metadata
        new_meta = [meta for meta in station.metadata
                    if meta.packet_start_mach_timestamp &lt; end_date_timestamp and
                    meta.packet_end_mach_timestamp &gt; start_date_timestamp]
        station.metadata = new_meta
        station.first_data_timestamp = start_date_timestamp
        station.last_data_timestamp = end_date_timestamp

    def create_data_window(self):
        &#34;&#34;&#34;
        updates the data window to contain only the data within the window parameters
        stations without audio or any data outside the window are removed
        &#34;&#34;&#34;

        ids_to_pop = []
        r_f = io.ReadFilter()
        if self.start_datetime:
            r_f.with_start_dt(self.start_datetime)
        if self.end_datetime:
            r_f.with_end_dt(self.end_datetime)
        if self.station_ids:
            r_f.with_station_ids(self.station_ids)
        if self.extensions:
            r_f.with_extensions(self.extensions)
        if self.start_buffer_td:
            r_f.with_start_dt_buf(self.start_buffer_td)
        if self.end_buffer_td:
            r_f.with_end_dt_buf(self.end_buffer_td)
        if self.api_versions:
            r_f.with_api_versions(self.api_versions)

        # get the data to convert into a window
        stations = ApiReader(
            self.input_directory,
            self.structured_layout,
            r_f,
            self.debug,
        ).get_stations()

        # Parallel update
        pool = parallel.pool()
        # Apply timing correction in parallel by station
        if self.apply_correction:
            stations = pool.map(Station.update_timestamps, stations)

        for station in stations:
            ids_to_pop = check_audio_data(station, ids_to_pop, self.debug)
            if station.id not in ids_to_pop:
                # set the window start and end if they were specified, otherwise use the bounds of the data
                if self.start_datetime:
                    start_datetime = dtu.datetime_to_epoch_microseconds_utc(self.start_datetime)
                else:
                    start_datetime = station.first_data_timestamp
                if self.end_datetime:
                    end_datetime = dtu.datetime_to_epoch_microseconds_utc(self.end_datetime)
                else:
                    end_datetime = station.last_data_timestamp
                # TRUNCATE!
                self.create_window_in_sensors(station, start_datetime, end_datetime)
                self.stations[station.id] = station
        # if user did not define station_ids, use the stations we have
        if self.station_ids is None or len(self.station_ids) == 0:
            self.station_ids = set(self.stations.keys())
        # check for stations without data, then remove any stations that don&#39;t have audio data
        self.check_valid_ids()


def check_audio_data(
    station: Station, ids_to_remove: List[str], debug: bool = False
) -&gt; List[str]:
    &#34;&#34;&#34;
    check if the station has audio data; if it does not, update the list of stations to remove
    :param station: station object to check for audio data
    :param ids_to_remove: list of station ids to remove from the data window
    :param debug: if True, output warning message, default False
    :return: an updated list of station ids to remove from the data window
    &#34;&#34;&#34;
    if not station.has_audio_sensor():
        if debug:
            print(f&#34;WARNING: {station.id} doesn&#39;t have any audio data to read&#34;)
        ids_to_remove.append(station.id)
    return ids_to_remove


def pad_data(
    expected_start: float,
    expected_end: float,
    data_df: pd.DataFrame,
    sample_interval_micros: float,
) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Pad the start and end of the dataframe with np.nan
    :param expected_start: timestamp indicating start time of the data to pad from
    :param expected_end: timestamp indicating end time of the data to pad from
    :param data_df: dataframe with timestamps as column &#34;timestamps&#34;
    :param sample_interval_micros: constant sample interval in microseconds
    :return: dataframe padded with np.nans in front and back to meet full size of expected start and end
    &#34;&#34;&#34;
    # extract the necessary information to pad the data
    data_time_stamps = data_df[&#34;timestamps&#34;].to_numpy()
    first_data_timestamp = data_time_stamps[0]
    last_data_timestamp = data_time_stamps[-1]
    result_df = data_df.copy()
    # FRONT/END GAP FILL!  calculate the audio samples missing based on inputs
    if expected_start &lt; first_data_timestamp:
        start_diff = first_data_timestamp - expected_start
        num_missing_samples = np.floor(start_diff / sample_interval_micros)
        if num_missing_samples &gt; 0:
            # add the gap data to the result dataframe
            result_df = result_df.append(
                create_dataless_timestamps_df(
                    first_data_timestamp,
                    sample_interval_micros,
                    data_df.columns,
                    num_missing_samples,
                    True
                ),
                ignore_index=True,
            )
    if expected_end &gt; last_data_timestamp:
        last_diff = expected_end - last_data_timestamp
        num_missing_samples = np.floor(last_diff / sample_interval_micros)
        if num_missing_samples &gt; 0:
            # add the gap data to the result dataframe
            result_df = result_df.append(
                create_dataless_timestamps_df(
                    last_data_timestamp,
                    sample_interval_micros,
                    data_df.columns,
                    num_missing_samples,
                ),
                ignore_index=True,
            )
    return result_df.sort_values(&#34;timestamps&#34;, ignore_index=True)


def fill_gaps(
    data_df: pd.DataFrame,
    sample_interval_micros: float,
    gap_time_micros: float,
    num_points_to_brute_force: int = DEFAULT_MAX_BRUTE_FORCE_GAP_TIMESTAMPS,
) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    fills gaps in the dataframe with np.nan by interpolating timestamps based on the mean expected sample interval
    :param data_df: dataframe with timestamps as column &#34;timestamps&#34;
    :param sample_interval_micros: sample interval in microseconds
    :param gap_time_micros: minimum amount of microseconds between data points that would indicate a gap
    :param num_points_to_brute_force: maximum number of points to calculate when filling a gap
    :return: dataframe without gaps
    &#34;&#34;&#34;
    # extract the necessary information to compute gap size and gap timestamps
    data_time_stamps = data_df[&#34;timestamps&#34;].to_numpy()
    first_data_timestamp = data_time_stamps[0]
    last_data_timestamp = data_time_stamps[-1]
    data_duration_micros = last_data_timestamp - first_data_timestamp
    num_points = len(data_time_stamps)
    # add one to calculation to include the last timestamp
    expected_num_points = np.ceil(data_duration_micros / sample_interval_micros) + 1
    # gap duration cannot be less than sample interval
    gap_time_micros = np.max([sample_interval_micros, gap_time_micros])
    result_df = data_df.copy()
    # if there are less points than our expected amount, we have gaps to fill
    if num_points &lt; expected_num_points:
        # if the data we&#39;re looking at is short enough, we can start comparing points
        if num_points &lt; num_points_to_brute_force:
            # look at every timestamp difference
            timestamp_diffs = np.diff(data_time_stamps)
            for index in np.where(timestamp_diffs &gt; gap_time_micros)[0]:
                # calc samples to add, subtracting 1 to prevent copying last timestamp
                num_new_samples = (
                    np.ceil(timestamp_diffs[index] / sample_interval_micros) - 1
                )
                if timestamp_diffs[index] &gt; gap_time_micros and num_new_samples &gt; 0:
                    # add the gap data to the result dataframe
                    result_df = result_df.append(
                        create_dataless_timestamps_df(
                            data_time_stamps[index],
                            sample_interval_micros,
                            data_df.columns,
                            num_new_samples,
                        ),
                        ignore_index=True,
                    )
                    if len(result_df) &gt;= expected_num_points:
                        break  # stop the for loop execution when enough points are added
        else:
            # too many points to check, divide and conquer using recursion!
            half_samples = int(num_points / 2)
            first_data_df = data_df.iloc[:half_samples].copy().reset_index(drop=True)
            second_data_df = data_df.iloc[half_samples:].copy().reset_index(drop=True)
            # give half the samples to each recursive call
            first_data_df = fill_gaps(
                first_data_df,
                sample_interval_micros,
                gap_time_micros,
                num_points_to_brute_force,
            )
            second_data_df = fill_gaps(
                second_data_df,
                sample_interval_micros,
                gap_time_micros,
                num_points_to_brute_force,
            )
            result_df = first_data_df.append(second_data_df, ignore_index=True)
    return result_df.sort_values(&#34;timestamps&#34;, ignore_index=True)


def create_dataless_timestamps_df(
    start_timestamp: float,
    sample_interval_micros: float,
    columns: pd.Index,
    num_samples_to_add: int,
    add_to_start: bool = False,
) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Creates an empty dataframe with num_samples_to_add timestamps, using columns as the columns
    the first timestamp created is 1 sample_interval_s from the start_timestamp
    :param start_timestamp: timestamp in microseconds since epoch UTC to start calculating other timestamps from
    :param sample_interval_micros: fixed sample interval in microseconds since epoch UTC
    :param columns: dataframe the non-timestamp columns of the dataframe
    :param num_samples_to_add: the number of timestamps to create
    :param add_to_start: if True, subtracts sample_interval_s from start_timestamp, default False
    :return: dataframe with timestamps and no data
    &#34;&#34;&#34;
    empty_df = pd.DataFrame([], columns=columns)
    if num_samples_to_add &gt; 0:
        if add_to_start:
            sample_interval_micros = -sample_interval_micros
        new_timestamps = (
            start_timestamp + np.arange(1, num_samples_to_add + 1) * sample_interval_micros
        )
        for column_index in columns:
            if column_index == &#34;timestamps&#34;:
                empty_df[column_index] = new_timestamps
            elif column_index == &#34;location_provider&#34;:
                empty_df[column_index] = LocationProvider.UNKNOWN
            elif column_index == &#34;image_codec&#34;:
                empty_df[column_index] = ImageCodec.UNKNOWN
            else:
                empty_df[column_index] = np.nan
    return empty_df</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="redvox.common.data_window.check_audio_data"><code class="name flex">
<span>def <span class="ident">check_audio_data</span></span>(<span>station: <a title="redvox.common.station.Station" href="station.html#redvox.common.station.Station">Station</a>, ids_to_remove: typing.List[str], debug: bool = False) ‑> typing.List[str]</span>
</code></dt>
<dd>
<div class="desc"><p>check if the station has audio data; if it does not, update the list of stations to remove
:param station: station object to check for audio data
:param ids_to_remove: list of station ids to remove from the data window
:param debug: if True, output warning message, default False
:return: an updated list of station ids to remove from the data window</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_audio_data(
    station: Station, ids_to_remove: List[str], debug: bool = False
) -&gt; List[str]:
    &#34;&#34;&#34;
    check if the station has audio data; if it does not, update the list of stations to remove
    :param station: station object to check for audio data
    :param ids_to_remove: list of station ids to remove from the data window
    :param debug: if True, output warning message, default False
    :return: an updated list of station ids to remove from the data window
    &#34;&#34;&#34;
    if not station.has_audio_sensor():
        if debug:
            print(f&#34;WARNING: {station.id} doesn&#39;t have any audio data to read&#34;)
        ids_to_remove.append(station.id)
    return ids_to_remove</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.create_dataless_timestamps_df"><code class="name flex">
<span>def <span class="ident">create_dataless_timestamps_df</span></span>(<span>start_timestamp: float, sample_interval_micros: float, columns: pandas.core.indexes.base.Index, num_samples_to_add: int, add_to_start: bool = False) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Creates an empty dataframe with num_samples_to_add timestamps, using columns as the columns
the first timestamp created is 1 sample_interval_s from the start_timestamp
:param start_timestamp: timestamp in microseconds since epoch UTC to start calculating other timestamps from
:param sample_interval_micros: fixed sample interval in microseconds since epoch UTC
:param columns: dataframe the non-timestamp columns of the dataframe
:param num_samples_to_add: the number of timestamps to create
:param add_to_start: if True, subtracts sample_interval_s from start_timestamp, default False
:return: dataframe with timestamps and no data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_dataless_timestamps_df(
    start_timestamp: float,
    sample_interval_micros: float,
    columns: pd.Index,
    num_samples_to_add: int,
    add_to_start: bool = False,
) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Creates an empty dataframe with num_samples_to_add timestamps, using columns as the columns
    the first timestamp created is 1 sample_interval_s from the start_timestamp
    :param start_timestamp: timestamp in microseconds since epoch UTC to start calculating other timestamps from
    :param sample_interval_micros: fixed sample interval in microseconds since epoch UTC
    :param columns: dataframe the non-timestamp columns of the dataframe
    :param num_samples_to_add: the number of timestamps to create
    :param add_to_start: if True, subtracts sample_interval_s from start_timestamp, default False
    :return: dataframe with timestamps and no data
    &#34;&#34;&#34;
    empty_df = pd.DataFrame([], columns=columns)
    if num_samples_to_add &gt; 0:
        if add_to_start:
            sample_interval_micros = -sample_interval_micros
        new_timestamps = (
            start_timestamp + np.arange(1, num_samples_to_add + 1) * sample_interval_micros
        )
        for column_index in columns:
            if column_index == &#34;timestamps&#34;:
                empty_df[column_index] = new_timestamps
            elif column_index == &#34;location_provider&#34;:
                empty_df[column_index] = LocationProvider.UNKNOWN
            elif column_index == &#34;image_codec&#34;:
                empty_df[column_index] = ImageCodec.UNKNOWN
            else:
                empty_df[column_index] = np.nan
    return empty_df</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.fill_gaps"><code class="name flex">
<span>def <span class="ident">fill_gaps</span></span>(<span>data_df: pandas.core.frame.DataFrame, sample_interval_micros: float, gap_time_micros: float, num_points_to_brute_force: int = 5000) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>fills gaps in the dataframe with np.nan by interpolating timestamps based on the mean expected sample interval
:param data_df: dataframe with timestamps as column "timestamps"
:param sample_interval_micros: sample interval in microseconds
:param gap_time_micros: minimum amount of microseconds between data points that would indicate a gap
:param num_points_to_brute_force: maximum number of points to calculate when filling a gap
:return: dataframe without gaps</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fill_gaps(
    data_df: pd.DataFrame,
    sample_interval_micros: float,
    gap_time_micros: float,
    num_points_to_brute_force: int = DEFAULT_MAX_BRUTE_FORCE_GAP_TIMESTAMPS,
) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    fills gaps in the dataframe with np.nan by interpolating timestamps based on the mean expected sample interval
    :param data_df: dataframe with timestamps as column &#34;timestamps&#34;
    :param sample_interval_micros: sample interval in microseconds
    :param gap_time_micros: minimum amount of microseconds between data points that would indicate a gap
    :param num_points_to_brute_force: maximum number of points to calculate when filling a gap
    :return: dataframe without gaps
    &#34;&#34;&#34;
    # extract the necessary information to compute gap size and gap timestamps
    data_time_stamps = data_df[&#34;timestamps&#34;].to_numpy()
    first_data_timestamp = data_time_stamps[0]
    last_data_timestamp = data_time_stamps[-1]
    data_duration_micros = last_data_timestamp - first_data_timestamp
    num_points = len(data_time_stamps)
    # add one to calculation to include the last timestamp
    expected_num_points = np.ceil(data_duration_micros / sample_interval_micros) + 1
    # gap duration cannot be less than sample interval
    gap_time_micros = np.max([sample_interval_micros, gap_time_micros])
    result_df = data_df.copy()
    # if there are less points than our expected amount, we have gaps to fill
    if num_points &lt; expected_num_points:
        # if the data we&#39;re looking at is short enough, we can start comparing points
        if num_points &lt; num_points_to_brute_force:
            # look at every timestamp difference
            timestamp_diffs = np.diff(data_time_stamps)
            for index in np.where(timestamp_diffs &gt; gap_time_micros)[0]:
                # calc samples to add, subtracting 1 to prevent copying last timestamp
                num_new_samples = (
                    np.ceil(timestamp_diffs[index] / sample_interval_micros) - 1
                )
                if timestamp_diffs[index] &gt; gap_time_micros and num_new_samples &gt; 0:
                    # add the gap data to the result dataframe
                    result_df = result_df.append(
                        create_dataless_timestamps_df(
                            data_time_stamps[index],
                            sample_interval_micros,
                            data_df.columns,
                            num_new_samples,
                        ),
                        ignore_index=True,
                    )
                    if len(result_df) &gt;= expected_num_points:
                        break  # stop the for loop execution when enough points are added
        else:
            # too many points to check, divide and conquer using recursion!
            half_samples = int(num_points / 2)
            first_data_df = data_df.iloc[:half_samples].copy().reset_index(drop=True)
            second_data_df = data_df.iloc[half_samples:].copy().reset_index(drop=True)
            # give half the samples to each recursive call
            first_data_df = fill_gaps(
                first_data_df,
                sample_interval_micros,
                gap_time_micros,
                num_points_to_brute_force,
            )
            second_data_df = fill_gaps(
                second_data_df,
                sample_interval_micros,
                gap_time_micros,
                num_points_to_brute_force,
            )
            result_df = first_data_df.append(second_data_df, ignore_index=True)
    return result_df.sort_values(&#34;timestamps&#34;, ignore_index=True)</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.pad_data"><code class="name flex">
<span>def <span class="ident">pad_data</span></span>(<span>expected_start: float, expected_end: float, data_df: pandas.core.frame.DataFrame, sample_interval_micros: float) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Pad the start and end of the dataframe with np.nan
:param expected_start: timestamp indicating start time of the data to pad from
:param expected_end: timestamp indicating end time of the data to pad from
:param data_df: dataframe with timestamps as column "timestamps"
:param sample_interval_micros: constant sample interval in microseconds
:return: dataframe padded with np.nans in front and back to meet full size of expected start and end</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pad_data(
    expected_start: float,
    expected_end: float,
    data_df: pd.DataFrame,
    sample_interval_micros: float,
) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Pad the start and end of the dataframe with np.nan
    :param expected_start: timestamp indicating start time of the data to pad from
    :param expected_end: timestamp indicating end time of the data to pad from
    :param data_df: dataframe with timestamps as column &#34;timestamps&#34;
    :param sample_interval_micros: constant sample interval in microseconds
    :return: dataframe padded with np.nans in front and back to meet full size of expected start and end
    &#34;&#34;&#34;
    # extract the necessary information to pad the data
    data_time_stamps = data_df[&#34;timestamps&#34;].to_numpy()
    first_data_timestamp = data_time_stamps[0]
    last_data_timestamp = data_time_stamps[-1]
    result_df = data_df.copy()
    # FRONT/END GAP FILL!  calculate the audio samples missing based on inputs
    if expected_start &lt; first_data_timestamp:
        start_diff = first_data_timestamp - expected_start
        num_missing_samples = np.floor(start_diff / sample_interval_micros)
        if num_missing_samples &gt; 0:
            # add the gap data to the result dataframe
            result_df = result_df.append(
                create_dataless_timestamps_df(
                    first_data_timestamp,
                    sample_interval_micros,
                    data_df.columns,
                    num_missing_samples,
                    True
                ),
                ignore_index=True,
            )
    if expected_end &gt; last_data_timestamp:
        last_diff = expected_end - last_data_timestamp
        num_missing_samples = np.floor(last_diff / sample_interval_micros)
        if num_missing_samples &gt; 0:
            # add the gap data to the result dataframe
            result_df = result_df.append(
                create_dataless_timestamps_df(
                    last_data_timestamp,
                    sample_interval_micros,
                    data_df.columns,
                    num_missing_samples,
                ),
                ignore_index=True,
            )
    return result_df.sort_values(&#34;timestamps&#34;, ignore_index=True)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="redvox.common.data_window.DataWindow"><code class="flex name class">
<span>class <span class="ident">DataWindow</span></span>
<span>(</span><span>input_dir: str, structured_layout: bool = True, start_datetime: typing.Union[datetime.datetime, NoneType] = None, end_datetime: typing.Union[datetime.datetime, NoneType] = None, start_buffer_td: datetime.timedelta = datetime.timedelta(seconds=120), end_buffer_td: datetime.timedelta = datetime.timedelta(seconds=120), gap_time_s: float = 0.25, station_ids: typing.Union[typing.Iterable[str], NoneType] = None, extensions: typing.Union[typing.Set[str], NoneType] = None, api_versions: typing.Union[typing.Set[<a title="redvox.common.versioning.ApiVersion" href="versioning.html#redvox.common.versioning.ApiVersion">ApiVersion</a>], NoneType] = None, apply_correction: bool = True, debug: bool = False)</span>
</code></dt>
<dd>
<div class="desc"><p>Holds the data for a given time window; adds interpolated timestamps to fill gaps and pad start and end values</p>
<h2 id="properties">Properties</h2>
<p>input_directory: string, directory that contains the files to read data from.
REQUIRED
structured_layout: bool, if True, the input_directory contains specially named and organized
directories of data.
Default True
station_ids: optional set of strings, representing the station ids to filter on.
If empty or None, get any ids found in the input directory.
Default None
extensions: optional set of strings, representing file extensions to filter on.
If None, gets as much data as it can in the input directory.
Default None
api_versions: optional set of ApiVersions, representing api versions to filter on.
If None, get as much data as it can in the input directory.
Default None
start_datetime: optional datetime, start datetime of the window.
If None, uses the first timestamp of the filtered data.
Default None
end_datetime: optional datetime, end datetime of the window.
If None, uses the last timestamp of the filtered data.
Default None
start_buffer_td: timedelta, the amount of time to include before the start_datetime when filtering data.
Default DEFAULT_START_BUFFER_TD
end_buffer_td: float, the amount of time to include after the end_datetime when filtering data.
Default DEFAULT_END_BUFFER_TD
gap_time_s: float, the minimum amount of seconds between data points that would indicate a gap.
Default DEFAULT_GAP_TIME_S
apply_correction: bool, if True, update the timestamps in the data based on best station offset.
Default True
stations: dictionary of Id:Station, the results of reading the data from input_directory
debug: bool, if True, outputs additional information during initialization. Default False</p>
<p>initialize the data window with params
:param input_dir: string, directory that contains the files to read data from
:param structured_layout: bool, if True, the input_directory contains specially named and organized
directories of data.
Default True
:param start_datetime: optional start datetime of the window. If None, uses the first timestamp of the
filtered data. Default None
:param end_datetime: optional end datetime of the window. If None, uses the last timestamp of the filtered
data.
Default None
:param start_buffer_td: the amount of time to include before the start_datetime when filtering data.
Default DEFAULT_START_BUFFER_TD
:param end_buffer_td: the amount of time to include after the end_datetime when filtering data.
Default DEFAULT_END_BUFFER_TD
:param gap_time_s: the minimum amount of seconds between data points that would indicate a gap.
Default DEFAULT_GAP_TIME_S
:param station_ids: optional iterable of station ids to filter on. If empty or None, get any ids found in the
input directory.
Default None
:param extensions: optional set of file extensions to filter on.
If None, get all data in the input directory.
Default None
:param api_versions: optional set of api versions to filter on.
If None, get all data in the input directory.
Default None
:param apply_correction: if True, update the timestamps in the data based on best station offset.
Default True
:param debug: bool, if True, outputs warnings and additional information, default False</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DataWindow:
    &#34;&#34;&#34;
    Holds the data for a given time window; adds interpolated timestamps to fill gaps and pad start and end values
    Properties:
        input_directory: string, directory that contains the files to read data from.  REQUIRED
        structured_layout: bool, if True, the input_directory contains specially named and organized
                            directories of data.  Default True
        station_ids: optional set of strings, representing the station ids to filter on.
                        If empty or None, get any ids found in the input directory.  Default None
        extensions: optional set of strings, representing file extensions to filter on.
                        If None, gets as much data as it can in the input directory.  Default None
        api_versions: optional set of ApiVersions, representing api versions to filter on.
                        If None, get as much data as it can in the input directory.  Default None
        start_datetime: optional datetime, start datetime of the window.
                        If None, uses the first timestamp of the filtered data.  Default None
        end_datetime: optional datetime, end datetime of the window.
                        If None, uses the last timestamp of the filtered data.  Default None
        start_buffer_td: timedelta, the amount of time to include before the start_datetime when filtering data.
                            Default DEFAULT_START_BUFFER_TD
        end_buffer_td: float, the amount of time to include after the end_datetime when filtering data.
                            Default DEFAULT_END_BUFFER_TD
        gap_time_s: float, the minimum amount of seconds between data points that would indicate a gap.
                    Default DEFAULT_GAP_TIME_S
        apply_correction: bool, if True, update the timestamps in the data based on best station offset.  Default True
        stations: dictionary of Id:Station, the results of reading the data from input_directory
        debug: bool, if True, outputs additional information during initialization. Default False
    &#34;&#34;&#34;

    def __init__(
        self,
        input_dir: str,
        structured_layout: bool = True,
        start_datetime: Optional[dtu.datetime] = None,
        end_datetime: Optional[dtu.datetime] = None,
        start_buffer_td: timedelta = DEFAULT_START_BUFFER_TD,
        end_buffer_td: timedelta = DEFAULT_END_BUFFER_TD,
        gap_time_s: float = DEFAULT_GAP_TIME_S,
        station_ids: Optional[Iterable[str]] = None,
        extensions: Optional[Set[str]] = None,
        api_versions: Optional[Set[io.ApiVersion]] = None,
        apply_correction: bool = True,
        debug: bool = False,
    ):
        &#34;&#34;&#34;
        initialize the data window with params
        :param input_dir: string, directory that contains the files to read data from
        :param structured_layout: bool, if True, the input_directory contains specially named and organized
                                    directories of data.  Default True
        :param start_datetime: optional start datetime of the window. If None, uses the first timestamp of the
                                filtered data. Default None
        :param end_datetime: optional end datetime of the window. If None, uses the last timestamp of the filtered
                                data.  Default None
        :param start_buffer_td: the amount of time to include before the start_datetime when filtering data.
                                Default DEFAULT_START_BUFFER_TD
        :param end_buffer_td: the amount of time to include after the end_datetime when filtering data.
                                Default DEFAULT_END_BUFFER_TD
        :param gap_time_s: the minimum amount of seconds between data points that would indicate a gap.
                            Default DEFAULT_GAP_TIME_S
        :param station_ids: optional iterable of station ids to filter on. If empty or None, get any ids found in the
                            input directory.  Default None
        :param extensions: optional set of file extensions to filter on.  If None, get all data in the input directory.
                            Default None
        :param api_versions: optional set of api versions to filter on.  If None, get all data in the input directory.
                                Default None
        :param apply_correction: if True, update the timestamps in the data based on best station offset.
                                    Default True
        :param debug: bool, if True, outputs warnings and additional information, default False
        &#34;&#34;&#34;

        self.input_directory: str = input_dir
        self.structured_layout: bool = structured_layout
        self.start_datetime: Optional[dtu.datetime] = start_datetime
        self.end_datetime: Optional[dtu.datetime] = end_datetime
        self.start_buffer_td: timedelta = start_buffer_td
        self.end_buffer_td: timedelta = end_buffer_td
        self.gap_time_s: float = gap_time_s
        self.station_ids: Optional[Set[str]]
        if station_ids:
            self.station_ids = set(station_ids)
        else:
            self.station_ids = None
        self.extensions: Optional[Set[str]] = extensions
        self.api_versions: Optional[Set[io.ApiVersion]] = api_versions
        self.apply_correction: bool = apply_correction
        self.debug: bool = debug
        self.stations: Dict[str, Station] = {}
        self.create_data_window()

    @staticmethod
    def from_config_file(file: str) -&gt; &#34;DataWindow&#34;:
        &#34;&#34;&#34;
        Loads a configuration file to create the DataWindow
        :param file: full path to config file
        :return: a data window
        &#34;&#34;&#34;
        return DataWindow.from_config(DataWindowConfig.from_path(file))

    @staticmethod
    def from_config(config: DataWindowConfig) -&gt; &#34;DataWindow&#34;:
        &#34;&#34;&#34;
        Loads a configuration to create the DataWindow
        :param config: DataWindow configuration object
        :return: a data window
        &#34;&#34;&#34;
        if config.start_year:
            start_time = dtu.datetime(
                year=config.start_year,
                month=config.start_month,
                day=config.start_day,
                hour=config.start_hour,
                minute=config.start_minute,
                second=config.start_second,
            )
        else:
            start_time = None
        if config.end_year:
            end_time = dtu.datetime(
                year=config.end_year,
                month=config.end_month,
                day=config.end_day,
                hour=config.end_hour,
                minute=config.end_minute,
                second=config.end_second,
            )
        else:
            end_time = None
        if config.api_versions:
            api_versions = set([io.ApiVersion.from_str(v) for v in config.api_versions])
        else:
            api_versions = None
        if config.extensions:
            extensions = set(config.extensions)
        else:
            extensions = None
        if config.station_ids:
            station_ids = set(config.station_ids)
        else:
            station_ids = None
        return DataWindow(
            config.input_directory,
            config.structured_layout,
            start_time,
            end_time,
            dtu.timedelta(seconds=config.start_padding_seconds),
            dtu.timedelta(seconds=config.end_padding_seconds),
            config.gap_time_seconds,
            station_ids,
            extensions,
            api_versions,
            config.apply_correction,
            config.debug,
        )

    def _has_time_window(self) -&gt; bool:
        &#34;&#34;&#34;
        Returns true if there is a start or end datetime in the settings
        :return: True if start_datetime or end_datetime exists
        &#34;&#34;&#34;
        return self.start_datetime is not None or self.end_datetime is not None

    def get_station(self, station_id: str) -&gt; Optional[Station]:
        &#34;&#34;&#34;
        Get a single station from the data window
        :param station_id: the id of the station to get
        :return: A single station or None if the station cannot be found
        &#34;&#34;&#34;
        if station_id in self.stations.keys():
            return self.stations[station_id]
        if self.debug:
            print(f&#34;Warning: Attempted to get station {station_id}, but that station is not in this data window!&#34;)
        return None

    def get_all_stations(self) -&gt; List[Station]:
        &#34;&#34;&#34;
        :return: all stations in the data window as a list
        &#34;&#34;&#34;
        return list(self.stations.values())

    def get_all_station_ids(self) -&gt; List[str]:
        &#34;&#34;&#34;
        :return: A list of all station ids with data
        &#34;&#34;&#34;
        return list(self.stations.keys())

    def check_valid_ids(self):
        &#34;&#34;&#34;
        searches the data window station_ids for any ids not in the data collected
        outputs a message for each id requested but has no data
        &#34;&#34;&#34;
        for ids in self.station_ids:
            if ids not in self.stations.keys() and self.debug:
                print(
                    f&#34;WARNING: Requested {ids} but there is no data to read for that station&#34;
                )

    def process_sensor(self, sensor: SensorData, station_id: str, start_date_timestamp: float,
                       end_date_timestamp: float):
        # calculate the sensor&#39;s sample interval, std sample interval and sample rate of all data
        sensor.organize_and_update_stats()
        # get only the timestamps between the start and end timestamps
        df_timestamps = sensor.data_timestamps()
        if len(df_timestamps) &gt; 0:
            window_indices = np.where(
                (start_date_timestamp &lt;= df_timestamps)
                &amp; (df_timestamps &lt;= end_date_timestamp)
            )[0]
            # check if all the samples have been cut off
            if len(window_indices) &lt; 1:
                if any(df_timestamps &lt; start_date_timestamp):
                    last_before_start = np.argwhere(df_timestamps &lt; start_date_timestamp)[-1][0]
                else:
                    last_before_start = None
                if any(df_timestamps &gt; end_date_timestamp):
                    first_after_end = np.argwhere(df_timestamps &gt; end_date_timestamp)[0][0]
                else:
                    first_after_end = None
                if last_before_start is not None and first_after_end is None:
                    sensor.data_df = sensor.data_df.iloc[last_before_start].to_frame().T
                    sensor.data_df[&#34;timestamps&#34;] = start_date_timestamp
                elif last_before_start is None and first_after_end is not None:
                    sensor.data_df = sensor.data_df.iloc[first_after_end].to_frame().T
                    sensor.data_df[&#34;timestamps&#34;] = end_date_timestamp
                elif last_before_start is not None and first_after_end is not None:
                    sensor.data_df = sensor.interpolate(last_before_start, first_after_end,
                                                        start_date_timestamp).to_frame().T
                elif self.debug:
                    print(
                        f&#34;WARNING: Data window for {station_id} {sensor.type.name} &#34;
                        f&#34;sensor has truncated all data points&#34;
                    )
            else:
                sensor.data_df = sensor.data_df.iloc[window_indices].reset_index(
                    drop=True
                )
                if sensor.is_sample_interval_invalid():
                    if self.debug:
                        print(
                            f&#34;WARNING: Cannot fill gaps or pad {station_id} {sensor.type.name} &#34;
                            f&#34;sensor; it has undefined sample interval and sample rate!&#34;
                        )
                else:  # GAP FILL and PAD DATA
                    sample_interval_micros = dtu.seconds_to_microseconds(sensor.sample_interval_s)
                    sensor.data_df = fill_gaps(
                        sensor.data_df,
                        sample_interval_micros + dtu.seconds_to_microseconds(sensor.sample_interval_std_s),
                        dtu.seconds_to_microseconds(self.gap_time_s),
                        DEFAULT_MAX_BRUTE_FORCE_GAP_TIMESTAMPS,
                        )
                    sensor.data_df = pad_data(
                        start_date_timestamp,
                        end_date_timestamp,
                        sensor.data_df,
                        sample_interval_micros,
                    )
        elif self.debug:
            print(f&#34;WARNING: Data window for {station_id} {sensor.type.name} sensor has no data points!&#34;)

    def create_window_in_sensors(
        self, station: Station, start_date_timestamp: float, end_date_timestamp: float
    ):
        &#34;&#34;&#34;
        truncate the sensors in the station to only contain data from start_date_timestamp to end_date_timestamp
        returns nothing, updates the station in place
        :param station: station object to truncate sensors of
        :param start_date_timestamp: timestamp in microseconds since epoch UTC of start of window
        :param end_date_timestamp: timestamp in microseconds since epoch UTC of end of window
        &#34;&#34;&#34;
        self.process_sensor(station.audio_sensor(), station.id, start_date_timestamp, end_date_timestamp)
        for sensor_type, sensor in station.data.items():
            if sensor_type != SensorType.AUDIO:
                self.process_sensor(sensor, station.id, station.audio_sensor().first_data_timestamp(),
                                    station.audio_sensor().last_data_timestamp())
        # recalculate metadata
        new_meta = [meta for meta in station.metadata
                    if meta.packet_start_mach_timestamp &lt; end_date_timestamp and
                    meta.packet_end_mach_timestamp &gt; start_date_timestamp]
        station.metadata = new_meta
        station.first_data_timestamp = start_date_timestamp
        station.last_data_timestamp = end_date_timestamp

    def create_data_window(self):
        &#34;&#34;&#34;
        updates the data window to contain only the data within the window parameters
        stations without audio or any data outside the window are removed
        &#34;&#34;&#34;

        ids_to_pop = []
        r_f = io.ReadFilter()
        if self.start_datetime:
            r_f.with_start_dt(self.start_datetime)
        if self.end_datetime:
            r_f.with_end_dt(self.end_datetime)
        if self.station_ids:
            r_f.with_station_ids(self.station_ids)
        if self.extensions:
            r_f.with_extensions(self.extensions)
        if self.start_buffer_td:
            r_f.with_start_dt_buf(self.start_buffer_td)
        if self.end_buffer_td:
            r_f.with_end_dt_buf(self.end_buffer_td)
        if self.api_versions:
            r_f.with_api_versions(self.api_versions)

        # get the data to convert into a window
        stations = ApiReader(
            self.input_directory,
            self.structured_layout,
            r_f,
            self.debug,
        ).get_stations()

        # Parallel update
        pool = parallel.pool()
        # Apply timing correction in parallel by station
        if self.apply_correction:
            stations = pool.map(Station.update_timestamps, stations)

        for station in stations:
            ids_to_pop = check_audio_data(station, ids_to_pop, self.debug)
            if station.id not in ids_to_pop:
                # set the window start and end if they were specified, otherwise use the bounds of the data
                if self.start_datetime:
                    start_datetime = dtu.datetime_to_epoch_microseconds_utc(self.start_datetime)
                else:
                    start_datetime = station.first_data_timestamp
                if self.end_datetime:
                    end_datetime = dtu.datetime_to_epoch_microseconds_utc(self.end_datetime)
                else:
                    end_datetime = station.last_data_timestamp
                # TRUNCATE!
                self.create_window_in_sensors(station, start_datetime, end_datetime)
                self.stations[station.id] = station
        # if user did not define station_ids, use the stations we have
        if self.station_ids is None or len(self.station_ids) == 0:
            self.station_ids = set(self.stations.keys())
        # check for stations without data, then remove any stations that don&#39;t have audio data
        self.check_valid_ids()</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="redvox.common.data_window.DataWindow.from_config"><code class="name flex">
<span>def <span class="ident">from_config</span></span>(<span>config: <a title="redvox.common.data_window_configuration.DataWindowConfig" href="data_window_configuration.html#redvox.common.data_window_configuration.DataWindowConfig">DataWindowConfig</a>) ‑> <a title="redvox.common.data_window.DataWindow" href="#redvox.common.data_window.DataWindow">DataWindow</a></span>
</code></dt>
<dd>
<div class="desc"><p>Loads a configuration to create the DataWindow
:param config: DataWindow configuration object
:return: a data window</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def from_config(config: DataWindowConfig) -&gt; &#34;DataWindow&#34;:
    &#34;&#34;&#34;
    Loads a configuration to create the DataWindow
    :param config: DataWindow configuration object
    :return: a data window
    &#34;&#34;&#34;
    if config.start_year:
        start_time = dtu.datetime(
            year=config.start_year,
            month=config.start_month,
            day=config.start_day,
            hour=config.start_hour,
            minute=config.start_minute,
            second=config.start_second,
        )
    else:
        start_time = None
    if config.end_year:
        end_time = dtu.datetime(
            year=config.end_year,
            month=config.end_month,
            day=config.end_day,
            hour=config.end_hour,
            minute=config.end_minute,
            second=config.end_second,
        )
    else:
        end_time = None
    if config.api_versions:
        api_versions = set([io.ApiVersion.from_str(v) for v in config.api_versions])
    else:
        api_versions = None
    if config.extensions:
        extensions = set(config.extensions)
    else:
        extensions = None
    if config.station_ids:
        station_ids = set(config.station_ids)
    else:
        station_ids = None
    return DataWindow(
        config.input_directory,
        config.structured_layout,
        start_time,
        end_time,
        dtu.timedelta(seconds=config.start_padding_seconds),
        dtu.timedelta(seconds=config.end_padding_seconds),
        config.gap_time_seconds,
        station_ids,
        extensions,
        api_versions,
        config.apply_correction,
        config.debug,
    )</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.from_config_file"><code class="name flex">
<span>def <span class="ident">from_config_file</span></span>(<span>file: str) ‑> <a title="redvox.common.data_window.DataWindow" href="#redvox.common.data_window.DataWindow">DataWindow</a></span>
</code></dt>
<dd>
<div class="desc"><p>Loads a configuration file to create the DataWindow
:param file: full path to config file
:return: a data window</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def from_config_file(file: str) -&gt; &#34;DataWindow&#34;:
    &#34;&#34;&#34;
    Loads a configuration file to create the DataWindow
    :param file: full path to config file
    :return: a data window
    &#34;&#34;&#34;
    return DataWindow.from_config(DataWindowConfig.from_path(file))</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="redvox.common.data_window.DataWindow.check_valid_ids"><code class="name flex">
<span>def <span class="ident">check_valid_ids</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>searches the data window station_ids for any ids not in the data collected
outputs a message for each id requested but has no data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_valid_ids(self):
    &#34;&#34;&#34;
    searches the data window station_ids for any ids not in the data collected
    outputs a message for each id requested but has no data
    &#34;&#34;&#34;
    for ids in self.station_ids:
        if ids not in self.stations.keys() and self.debug:
            print(
                f&#34;WARNING: Requested {ids} but there is no data to read for that station&#34;
            )</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.create_data_window"><code class="name flex">
<span>def <span class="ident">create_data_window</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>updates the data window to contain only the data within the window parameters
stations without audio or any data outside the window are removed</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_data_window(self):
    &#34;&#34;&#34;
    updates the data window to contain only the data within the window parameters
    stations without audio or any data outside the window are removed
    &#34;&#34;&#34;

    ids_to_pop = []
    r_f = io.ReadFilter()
    if self.start_datetime:
        r_f.with_start_dt(self.start_datetime)
    if self.end_datetime:
        r_f.with_end_dt(self.end_datetime)
    if self.station_ids:
        r_f.with_station_ids(self.station_ids)
    if self.extensions:
        r_f.with_extensions(self.extensions)
    if self.start_buffer_td:
        r_f.with_start_dt_buf(self.start_buffer_td)
    if self.end_buffer_td:
        r_f.with_end_dt_buf(self.end_buffer_td)
    if self.api_versions:
        r_f.with_api_versions(self.api_versions)

    # get the data to convert into a window
    stations = ApiReader(
        self.input_directory,
        self.structured_layout,
        r_f,
        self.debug,
    ).get_stations()

    # Parallel update
    pool = parallel.pool()
    # Apply timing correction in parallel by station
    if self.apply_correction:
        stations = pool.map(Station.update_timestamps, stations)

    for station in stations:
        ids_to_pop = check_audio_data(station, ids_to_pop, self.debug)
        if station.id not in ids_to_pop:
            # set the window start and end if they were specified, otherwise use the bounds of the data
            if self.start_datetime:
                start_datetime = dtu.datetime_to_epoch_microseconds_utc(self.start_datetime)
            else:
                start_datetime = station.first_data_timestamp
            if self.end_datetime:
                end_datetime = dtu.datetime_to_epoch_microseconds_utc(self.end_datetime)
            else:
                end_datetime = station.last_data_timestamp
            # TRUNCATE!
            self.create_window_in_sensors(station, start_datetime, end_datetime)
            self.stations[station.id] = station
    # if user did not define station_ids, use the stations we have
    if self.station_ids is None or len(self.station_ids) == 0:
        self.station_ids = set(self.stations.keys())
    # check for stations without data, then remove any stations that don&#39;t have audio data
    self.check_valid_ids()</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.create_window_in_sensors"><code class="name flex">
<span>def <span class="ident">create_window_in_sensors</span></span>(<span>self, station: <a title="redvox.common.station.Station" href="station.html#redvox.common.station.Station">Station</a>, start_date_timestamp: float, end_date_timestamp: float)</span>
</code></dt>
<dd>
<div class="desc"><p>truncate the sensors in the station to only contain data from start_date_timestamp to end_date_timestamp
returns nothing, updates the station in place
:param station: station object to truncate sensors of
:param start_date_timestamp: timestamp in microseconds since epoch UTC of start of window
:param end_date_timestamp: timestamp in microseconds since epoch UTC of end of window</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_window_in_sensors(
    self, station: Station, start_date_timestamp: float, end_date_timestamp: float
):
    &#34;&#34;&#34;
    truncate the sensors in the station to only contain data from start_date_timestamp to end_date_timestamp
    returns nothing, updates the station in place
    :param station: station object to truncate sensors of
    :param start_date_timestamp: timestamp in microseconds since epoch UTC of start of window
    :param end_date_timestamp: timestamp in microseconds since epoch UTC of end of window
    &#34;&#34;&#34;
    self.process_sensor(station.audio_sensor(), station.id, start_date_timestamp, end_date_timestamp)
    for sensor_type, sensor in station.data.items():
        if sensor_type != SensorType.AUDIO:
            self.process_sensor(sensor, station.id, station.audio_sensor().first_data_timestamp(),
                                station.audio_sensor().last_data_timestamp())
    # recalculate metadata
    new_meta = [meta for meta in station.metadata
                if meta.packet_start_mach_timestamp &lt; end_date_timestamp and
                meta.packet_end_mach_timestamp &gt; start_date_timestamp]
    station.metadata = new_meta
    station.first_data_timestamp = start_date_timestamp
    station.last_data_timestamp = end_date_timestamp</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.get_all_station_ids"><code class="name flex">
<span>def <span class="ident">get_all_station_ids</span></span>(<span>self) ‑> typing.List[str]</span>
</code></dt>
<dd>
<div class="desc"><p>:return: A list of all station ids with data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_all_station_ids(self) -&gt; List[str]:
    &#34;&#34;&#34;
    :return: A list of all station ids with data
    &#34;&#34;&#34;
    return list(self.stations.keys())</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.get_all_stations"><code class="name flex">
<span>def <span class="ident">get_all_stations</span></span>(<span>self) ‑> typing.List[<a title="redvox.common.station.Station" href="station.html#redvox.common.station.Station">Station</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>:return: all stations in the data window as a list</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_all_stations(self) -&gt; List[Station]:
    &#34;&#34;&#34;
    :return: all stations in the data window as a list
    &#34;&#34;&#34;
    return list(self.stations.values())</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.get_station"><code class="name flex">
<span>def <span class="ident">get_station</span></span>(<span>self, station_id: str) ‑> typing.Union[<a title="redvox.common.station.Station" href="station.html#redvox.common.station.Station">Station</a>, NoneType]</span>
</code></dt>
<dd>
<div class="desc"><p>Get a single station from the data window
:param station_id: the id of the station to get
:return: A single station or None if the station cannot be found</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_station(self, station_id: str) -&gt; Optional[Station]:
    &#34;&#34;&#34;
    Get a single station from the data window
    :param station_id: the id of the station to get
    :return: A single station or None if the station cannot be found
    &#34;&#34;&#34;
    if station_id in self.stations.keys():
        return self.stations[station_id]
    if self.debug:
        print(f&#34;Warning: Attempted to get station {station_id}, but that station is not in this data window!&#34;)
    return None</code></pre>
</details>
</dd>
<dt id="redvox.common.data_window.DataWindow.process_sensor"><code class="name flex">
<span>def <span class="ident">process_sensor</span></span>(<span>self, sensor: <a title="redvox.common.sensor_data.SensorData" href="sensor_data.html#redvox.common.sensor_data.SensorData">SensorData</a>, station_id: str, start_date_timestamp: float, end_date_timestamp: float)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def process_sensor(self, sensor: SensorData, station_id: str, start_date_timestamp: float,
                   end_date_timestamp: float):
    # calculate the sensor&#39;s sample interval, std sample interval and sample rate of all data
    sensor.organize_and_update_stats()
    # get only the timestamps between the start and end timestamps
    df_timestamps = sensor.data_timestamps()
    if len(df_timestamps) &gt; 0:
        window_indices = np.where(
            (start_date_timestamp &lt;= df_timestamps)
            &amp; (df_timestamps &lt;= end_date_timestamp)
        )[0]
        # check if all the samples have been cut off
        if len(window_indices) &lt; 1:
            if any(df_timestamps &lt; start_date_timestamp):
                last_before_start = np.argwhere(df_timestamps &lt; start_date_timestamp)[-1][0]
            else:
                last_before_start = None
            if any(df_timestamps &gt; end_date_timestamp):
                first_after_end = np.argwhere(df_timestamps &gt; end_date_timestamp)[0][0]
            else:
                first_after_end = None
            if last_before_start is not None and first_after_end is None:
                sensor.data_df = sensor.data_df.iloc[last_before_start].to_frame().T
                sensor.data_df[&#34;timestamps&#34;] = start_date_timestamp
            elif last_before_start is None and first_after_end is not None:
                sensor.data_df = sensor.data_df.iloc[first_after_end].to_frame().T
                sensor.data_df[&#34;timestamps&#34;] = end_date_timestamp
            elif last_before_start is not None and first_after_end is not None:
                sensor.data_df = sensor.interpolate(last_before_start, first_after_end,
                                                    start_date_timestamp).to_frame().T
            elif self.debug:
                print(
                    f&#34;WARNING: Data window for {station_id} {sensor.type.name} &#34;
                    f&#34;sensor has truncated all data points&#34;
                )
        else:
            sensor.data_df = sensor.data_df.iloc[window_indices].reset_index(
                drop=True
            )
            if sensor.is_sample_interval_invalid():
                if self.debug:
                    print(
                        f&#34;WARNING: Cannot fill gaps or pad {station_id} {sensor.type.name} &#34;
                        f&#34;sensor; it has undefined sample interval and sample rate!&#34;
                    )
            else:  # GAP FILL and PAD DATA
                sample_interval_micros = dtu.seconds_to_microseconds(sensor.sample_interval_s)
                sensor.data_df = fill_gaps(
                    sensor.data_df,
                    sample_interval_micros + dtu.seconds_to_microseconds(sensor.sample_interval_std_s),
                    dtu.seconds_to_microseconds(self.gap_time_s),
                    DEFAULT_MAX_BRUTE_FORCE_GAP_TIMESTAMPS,
                    )
                sensor.data_df = pad_data(
                    start_date_timestamp,
                    end_date_timestamp,
                    sensor.data_df,
                    sample_interval_micros,
                )
    elif self.debug:
        print(f&#34;WARNING: Data window for {station_id} {sensor.type.name} sensor has no data points!&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="redvox.common" href="index.html">redvox.common</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="redvox.common.data_window.check_audio_data" href="#redvox.common.data_window.check_audio_data">check_audio_data</a></code></li>
<li><code><a title="redvox.common.data_window.create_dataless_timestamps_df" href="#redvox.common.data_window.create_dataless_timestamps_df">create_dataless_timestamps_df</a></code></li>
<li><code><a title="redvox.common.data_window.fill_gaps" href="#redvox.common.data_window.fill_gaps">fill_gaps</a></code></li>
<li><code><a title="redvox.common.data_window.pad_data" href="#redvox.common.data_window.pad_data">pad_data</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="redvox.common.data_window.DataWindow" href="#redvox.common.data_window.DataWindow">DataWindow</a></code></h4>
<ul class="">
<li><code><a title="redvox.common.data_window.DataWindow.check_valid_ids" href="#redvox.common.data_window.DataWindow.check_valid_ids">check_valid_ids</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.create_data_window" href="#redvox.common.data_window.DataWindow.create_data_window">create_data_window</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.create_window_in_sensors" href="#redvox.common.data_window.DataWindow.create_window_in_sensors">create_window_in_sensors</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.from_config" href="#redvox.common.data_window.DataWindow.from_config">from_config</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.from_config_file" href="#redvox.common.data_window.DataWindow.from_config_file">from_config_file</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.get_all_station_ids" href="#redvox.common.data_window.DataWindow.get_all_station_ids">get_all_station_ids</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.get_all_stations" href="#redvox.common.data_window.DataWindow.get_all_stations">get_all_stations</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.get_station" href="#redvox.common.data_window.DataWindow.get_station">get_station</a></code></li>
<li><code><a title="redvox.common.data_window.DataWindow.process_sensor" href="#redvox.common.data_window.DataWindow.process_sensor">process_sensor</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>